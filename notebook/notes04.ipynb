{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLLib Development Notes\n",
    "April 2022\n",
    "\n",
    "Reverse time order - Newest on top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 April 2022\n",
    "- Training LIT\n",
    "- Increasing the learning rate 1 2e-4 appears to have pushed the model convergence to train the network to find nothing - always background\n",
    "- There is a heavy class imbalance\n",
    "- Adding class weighting to full training\n",
    "- Next work on switching datasets with parameter\n",
    "- Add cityscapes dataset\n",
    "- Add denoise dataset\n",
    "- Pytorch [Dataset and Dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "- Uses: load, split, train, test, view\n",
    "- [datasets/cocostore.py](../datasets/cocostore.py) - loads coco into torch dataset from S3\n",
    "- [datasets/imstore.py](../datasets/imstore.py) - loads directories of images into torch dataset\n",
    "- [dataset/citytorch.py](../datasets/citytorch.py) - loads cityscapes to a torch dataset \n",
    "- [OpenImages dataset](https://storage.googleapis.com/openimages/web/factsfigures.html)\n",
    "- Disable augmentation on validation images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 April 2022\n",
    "- Scale annealing and prune basis based on start & end points.  \n",
    "- Switch to exponential function where start and end point are specified\n",
    "- Initially grow based on epochs\n",
    "- Experiment with growing based on step to make training more independent of dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 April 2022\n",
    "- CRISP training with pruning basis function crisplit_20220401i_pb00_\n",
    "- Pruned 94% of network while increasing segmentation similarity\n",
    "- May achieve~ 25X speedup\n",
    "- Pruning search not strictly 1 and 0.  \n",
    "\n",
    "\n",
    "[T00cw]: ../img/crisplit_20220401i_pb00_00_cw.png\n",
    "[T01cw]: ../img/crisplit_20220401i_pb00_01_cw.png\n",
    "[T02cw]: ../img/crisplit_20220401i_pb00_02_cw.png\n",
    "[T03cw]: ../img/crisplit_20220401i_pb00_03_cw.png\n",
    "[T00gn]: ../img/crisplit_20220401i_pb00_00_gn.png\n",
    "[T01gn]: ../img/crisplit_20220401i_pb00_01_gn.png\n",
    "[T02gn]: ../img/crisplit_20220401i_pb00_02_gn.png\n",
    "[T03gn]: ../img/crisplit_20220401i_pb00_03_gn.png\n",
    "|  | normalized-train | train | train_fine | prune |\n",
    "|:--:|:--:|:--:|:--:|:--:|\n",
    "|Cross Entropy Loss|0.163|0.0068|0.0112|0.005|\n",
    "|Reamining Ratio   |1.0  |0.132 |0.131 |0.057|\n",
    "|Test similarity   |     |      |0.113 |0.817|\n",
    "| Prune Weights |![][T00cw]|![][T01cw] |![][T02cw] |![][T03cw]|\n",
    "| Gradient Norm |![][T00gn]|![][T01gn] |![][T02gn] |![][T03gn]|\n",
    "\n",
    "- Final losses before pruning:\n",
    "\n",
    "| Loss               | Value    |\n",
    "|:------------------:|:--------:|\n",
    "| cross_entropy_loss | 0.011264 |\n",
    "| architecture_loss  | 0.001306 |\n",
    "| prune_loss         | 0.000196 |\n",
    "\n",
    "- Increasing prune loss should incrase this sepration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class Exponential():\n",
    "    def __init__(self,vx=0.0, vy=0.0, px=1.0, py=1.0, power=2.0):\n",
    "        self.vx = vx\n",
    "        self.vy = vy\n",
    "        self.px = px\n",
    "        self.py = py\n",
    "        if power < 0:\n",
    "            raise ValueError('Exponential error power {} must be >= 0'.format(power))\n",
    "        self.power = power\n",
    "        if px <= vx:\n",
    "            raise ValueError('Exponential error px={} must be > vx'.format(px, vx))\n",
    "        else:\n",
    "            self.a = (py-vy)/np.power(px-vx,power)\n",
    "    def f(self, x):\n",
    "        dx = x-self.vx\n",
    "        y = self.a*np.power(x-self.vx,self.power) + self.vy\n",
    "        return y\n",
    "\n",
    "vx = -1\n",
    "px = 1\n",
    "expf =  Exponential(vx=vx, vy=0.0, px=px, py=1.0, power=2.0)\n",
    "\n",
    "x = np.arange(vx, px, 0.01)\n",
    "plt.plot(x, expf.f(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 April 2022\n",
    "- Prune loss basis function training to 0 size\n",
    "- This resulted in much more agressive pruning\n",
    "- Slightly worse cross entropy loss for train and train_fine\n",
    "- Much worse cross entropy loss for pruned network\n",
    "- The tensorboard plots show a similar timing of the architecture reduction curves but with prune_loss, the architecture settles at a lower level.\n",
    "- Architecture reduction occurs early and converges rapidly compared to cross entropy loss.  \n",
    "- Reduce k_structure from 0.03 to 0.1 to slow architecture search\n",
    "- Increase k_prune_basis from 0.01 to 0.3 to see if the resuls in eliminating fence sittes more effectively\n",
    "- Increase k_prune_exp from 5.0 to 50.0 apply prunce basis later in training\n",
    "\n",
    "[T00cw]: ../img/crisplit_20220331h_pb0_00_cw.png\n",
    "[T01cw]: ../img/crisplit_20220331h_pb0_01_cw.png\n",
    "[T02cw]: ../img/crisplit_20220331h_pb0_02_cw.png\n",
    "[T03cw]: ../img/crisplit_20220331h_pb0_03_cw.png\n",
    "[T00gn]: ../img/crisplit_20220331h_pb0_00_gn.png\n",
    "[T01gn]: ../img/crisplit_20220331h_pb0_01_gn.png\n",
    "[T02gn]: ../img/crisplit_20220331h_pb0_02_gn.png\n",
    "[T03gn]: ../img/crisplit_20220331h_pb0_03_gn.png\n",
    "|  | normalized-train | train | train_fine | prune |\n",
    "|:--:|:--:|:--:|:--:|:--:|\n",
    "|Cross Entropy Loss|0.164|0.032|0.020|0.040|\n",
    "|Reamining Ratio|1.0|0.050|0.041|0.00024|\n",
    "|Test similarity|  |  |0.106|0.028|\n",
    "| Prune Weights |![][T00cw]|![][T01cw] |![][T02cw] |![][T03cw]|\n",
    "| Gradient Norm |![][T00gn]|![][T01gn] |![][T02gn] |![][T03gn]|\n",
    "\n",
    "- Signmod scale as linear function stiffens very quickly.  Want it to be gradual at the beginning and stiffen towards the end of the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def SigmoidScale(step, start_x = 0, end_x = 25, start_y = 0, end_y=100):\n",
    "    kSigmoid = start_y + (end_y-start_y)*step/(end_x-start_x)\n",
    "    return kSigmoid\n",
    "x = np.arange(0.0, 30.0, 0.01)\n",
    "k_prune_exp = 1\n",
    "sigmoid_scale = 5\n",
    "sigmoid_scale_exp = 0.25\n",
    "plt.plot(x, SigmoidScale(x, end_x=25, end_y=150))\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(-1.0, 1.0, 0.01)\n",
    "step =3\n",
    "kSigmoid = SigmoidScale(step, end_x=25, end_y=150)\n",
    "print('kSigmoid({})={}'.format(step, kSigmoid))\n",
    "plt.plot(x, sigmoid(x, k=kSigmoid))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 April 2022\n",
    "- Added imstore.py CreateDataLoaders to load unique datasets for any number of sets with unique parameters \n",
    "- Moving imstore common processing to ImUtil\n",
    "- Move into  library for dataset loading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13 April 2022\n",
    "- updated [pymlutil](https://github.com/bhlarson/pymlutil) to deliver new tag and pipy version when excuting ./setup\n",
    "- Added pattern for documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 May 2022\n",
    "- The past couple of weeks, I have been splitting off code \n",
    "- The python library [pymlutil](https://pypi.org/project/pymlutil/) contains general utility functions\n",
    "- The python library [torchdatasetuitl](https://pypi.org/project/torchdatasetutil/) contains creating and using datasets\n",
    "- I will be removing this code from pymlutil soon.\n",
    "- One goal for this is to enable the dataset to be selected as a parameter\n",
    "- To do this the input channels and format must to be specified in the network creation.\n",
    "- I am adding class_dictionary['input_channels'] and class_dictionary['input_type'] to the class_dictionary.  This way, selecting the class dictionary defines the input type\n",
    "- If the input dataset can be selected by parameter rather than requiring code changes, I would like to enable transfer learning across training sets.\n",
    "- I would like to pick up the Torch pretrained [UNET](https://pytorch.org/hub/mateuszbuda_brain-segmentation-pytorch_unet/) and [Deeplab V3](https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/)\n",
    "- To enable transfer learning, I need to change from torch.load to model.load_state_dict: https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html\n",
    "- torch.load loads the pickled python object which I needed to do previously because pruned state in class variables - e.g. - convolution size after pruning is complete\n",
    "- Transfer learning only may only work for unpruned models\n",
    "- After a model is pruned, how would transfer learning from an unpruned model work?  \n",
    "    - require model pruning weights\n",
    "    - copy parameters based on pruning weights\n",
    "    - easier and same result if you initialize the model just before pruning,\n",
    "    - initialize parameters from transfer learning\n",
    "    - prune model with weights from transfer learning\n",
    "\n",
    "    \"input_channels\":3,\n",
    "    \"input_type\": \"float32\",\n",
    "- For transfer learning, need to handle changes in input channel depth from 1 to 3 and visa versa - for datasets with grayscale and RGB inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 May 2022\n",
    "- CRISP training of UNET on the LIT dataset takes a few hours\n",
    "- The same parameters on COCO take a few days\n",
    "- The COCO dataset is much more diverse than the LIT dataset\n",
    "- The COCO dataset is 100x larger than the LIT dataset\n",
    "- A6000 GPU efficiency is 70% on COCO\n",
    "- I am only using half the available A6000 memory.  Increasing this should reduce the training time\n",
    "- Look at Deeplab V3 with CRISP"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
