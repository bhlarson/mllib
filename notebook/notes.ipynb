{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b409663-308c-43dc-8eb6-0cd92927c070",
   "metadata": {},
   "source": [
    "# Test Notes in Jupyter\n",
    "\n",
    "I am looking for a method to keep an electronic design notebook where I can keep a design log, live evqations, plots, and drawings.  Here I am trying to do this in Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a352506-c467-4dc5-a886-b16d9562ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1300c909-1929-4de1-87b2-37d22803d2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\int e^{x} \\cos{\\left(x \\right)}\\, dx = \\frac{e^{x} \\sin{\\left(x \\right)}}{2} + \\frac{e^{x} \\cos{\\left(x \\right)}}{2}$"
      ],
      "text/plain": [
       "Eq(Integral(exp(x)*cos(x), x), exp(x)*sin(x)/2 + exp(x)*cos(x)/2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = symbols('x')\n",
    "a = Integral(cos(x)*exp(x), x)\n",
    "Eq(a, a.doit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d3b938-66a1-43a2-8690-4032e78311c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.0, 2*np.pi, 0.01) \n",
    "y = np.sin(x) \n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed1c670",
   "metadata": {},
   "source": [
    "4 January 2022\n",
    "- cell2d is no longer optimizing the network to minimize convolution norm\n",
    "- I suspect that summing convolution weights is losing the tensor gradient \n",
    "- See [Pytorch: backpropagating from sum of matrix elements to leaf variable answer](https://stackoverflow.com/questions/55942423/pytorch-backpropagating-from-sum-of-matrix-elements-to-leaf-variable)\n",
    "- Next: build up architecture loss concatenating tensors from lower networl level: c = torch.cat([a,b])\n",
    "- Next: solve architecture level using torch sum: d = torch.sum(c)\n",
    "- Next: verify gradient throughout operation\n",
    "- Next: test convolution minimization\n",
    "- Next: enable residual bypass of a specific level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a695d9f0-6f06-4fa4-979a-55b2ddc389d7",
   "metadata": {},
   "source": [
    "6 January 2022\n",
    "- Pruning successful\n",
    "- Failied to run with pruned network nas_20220104_01:\\\n",
    "- Exception has occurred: RuntimeError       (note: full exception trace is shown but execution is paused at: <module>)\n",
    "Given groups=1, weight of size [982, 1023, 1, 1], expected input[256, 1024, 8, 8] to have 1023 channels, but got 1024 channels instead\n",
    "- The pruned convolution size is not fully propegated to the next convolution from Cell->ConvBR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d169c1a",
   "metadata": {},
   "source": [
    "7 January 2022\n",
    "- Test cross entropy loss is ~ 0.01\n",
    "- Architecture loss is ~ 0.01\n",
    "- The architecture reduction pushing from 0.1 to 0.01 requests a much smaller model but has a very small loss\n",
    "- Change from mean squared error to absolute error\n",
    "<br /> ![Tensorboard](../img/Tensorboard_nas_20220106_01.png) <br />\n",
    "- How to boost baseline accuracy to the state of the art? \n",
    "- [Cutmix](https://openaccess.thecvf.com/content_ICCV_2019/papers/Yun_CutMix_Regularization_Strategy_to_Train_Strong_Classifiers_With_Localizable_Features_ICCV_2019_paper.pdf)\n",
    "- [Attentive CutMix](https://arxiv.org/pdf/2003.13048.pdf)\n",
    "- [Label smoothing](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf)\n",
    "- [Mish activation function](https://arxiv.org/pdf/1908.08681v3.pdf)\n",
    "- Comminting out Cell::ApplyStructure enabled training following pruning: <br />\n",
    "            #if self.convolutions[-1]['out_channels'] == self.in1_channels+self.in2_channels:\n",
    "            #    self.conv_residual = None\n",
    "- On second ApplyStructure call, I get the following error: <br />\n",
    "  File \"networks/cell2d.py\", line 164, in ApplyStructure\n",
    "    raise ValueError(\"len(out_channel_mask)={} must be equal to self.out_channels={}\".format(len(out_channel_mask), self.out_channels))\n",
    "ValueError: len(out_channel_mask)=253 must be equal to self.out_channels=256\n",
    "- Find why self.out_channels is not updated in second training?\n",
    "- Found and fixed incorrect self.out_channels propagation on pruned cells\n",
    "- Training after prune resulted in all of the higher level convolutions being pruned out.\n",
    "- With higher levels pruned, the test accuracy peeked at about 50% rather than ~ 80%\n",
    "<br /> ![nas_20220106_03 training Tensorboard](../img/class_weights_nas_20220106_03.png) <br />\n",
    "<br /> ![nas_20220106_03 training Tensorboard](../img/TrainingAfterPrune_nas_20220106_03.png) <br />\n",
    "- Why did the test accuracy peek earlier in a pruned network while the training accuracy continued to climb with just the lower level convolutions?\n",
    "- What in the deeper network structure enables the training and test accuracies to track better?\n",
    "- Can I capture that good to keep the training and test accuracy together for longer?\n",
    "- Try reducing size by reducing convolutions but not removing layers.\n",
    "- Removing layer removal resulted in a significant decay of the middle layers and a similar test accuracy before pruning.  Test loss diverged from training loss after about iteration 4000\n",
    "<br /> ![nas_20220107_00 training NAS sweights](../img/nas_20220107_00_cw.png <br />\n",
    "<br /> ![nas_20220107_00 training Tensorboard](../img/nas_20220107_00_tb.png) <br />\n",
    "- Runtime error:\n",
    "```console\n",
    "Total Trainable Params: 22467463\n",
    "Reduced parameters 22467463/38108762 = 0.5895616079052896\n",
    "Train steps:   0%|                                                                                                                                                             | 0/250.0 [00:01<?, ?it/s]\n",
    "Train epochs:   0%|                                                                                                                                                               | 0/50 [00:01<?, ?it/s]\n",
    "Traceback (most recent call last):\n",
    "  File \"networks/cell2d.py\", line 987, in <module>\n",
    "    result = Test(args)\n",
    "  File \"networks/cell2d.py\", line 886, in Test\n",
    "    outputs = classify(inputs)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
    "    return forward_call(*input, **kwargs)\n",
    "  File \"networks/cell2d.py\", line 634, in forward\n",
    "    x = self.fc(x)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
    "    return forward_call(*input, **kwargs)\n",
    "  File \"networks/cell2d.py\", line 466, in forward\n",
    "    y = self.fc(x)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
    "    return forward_call(*input, **kwargs)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 103, in forward\n",
    "    return F.linear(input, self.weight, self.bias)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\", line 1947, in linear\n",
    "    return torch._C._nn.linear(input, weight, bias)\n",
    "RuntimeError: mat1 and mat2 shapes cannot be multiplied (200x1449 and 2048x10)\n",
    "PlotSearch finish\n",
    "```\n",
    "- Added dropout improved cross entropy loss compared with nas_20220107_00\n",
    "<br /> ![nas_20220107_dropout_00 training weights](../img/nas_20220107_dropout_00_cw.png) <br />\n",
    "<br /> ![nas_20220107_dropout_00 Tensorboard](../img/nas_20220107_dropout_00_tb.png) <br />\n",
    "- Try pruning and training.\n",
    "- Failed running following pruning\n",
    "```cmd\n",
    "Total Trainable Params: 27624300\n",
    "Reduced parameters 27624300/38108762 = 0.7248805405958871\n",
    "Train steps:   0%|                                                                                                                                                             | 0/250.0 [00:01<?, ?it/s]\n",
    "Train epochs:   0%|                                                                                                                                                               | 0/50 [00:01<?, ?it/s]\n",
    "Traceback (most recent call last):\n",
    "  File \"networks/cell2d.py\", line 993, in <module>\n",
    "    result = Test(args)\n",
    "  File \"networks/cell2d.py\", line 892, in Test\n",
    "    outputs = classify(inputs, isTraining=True)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
    "    return forward_call(*input, **kwargs)\n",
    "  File \"networks/cell2d.py\", line 639, in forward\n",
    "    x = self.fc(x)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
    "    return forward_call(*input, **kwargs)\n",
    "  File \"networks/cell2d.py\", line 471, in forward\n",
    "    y = self.fc(x)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
    "    return forward_call(*input, **kwargs)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 103, in forward\n",
    "    return F.linear(input, self.weight, self.bias)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\", line 1947, in linear\n",
    "    return torch._C._nn.linear(input, weight, bias)\n",
    "RuntimeError: mat1 and mat2 shapes cannot be multiplied (200x1712 and 2048x10)\n",
    "PlotSearch finish\n",
    "```\n",
    "- Pass the input size to FC::ApplyStructure from Classify::ApplyStructure\n",
    "- Initial training following pruning preserved accuracy:\n",
    "```cmd\n",
    "Total Trainable Params: 27620940\n",
    "Reduced parameters 27620940/38108762 = 0.724792371895996\n",
    "Train epochs:   0%|                                                                                                                                                                                        | 0/50 [00:00<?, ?it/s/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
    "  return F.l1_loss(input, target, reduction=self.reduction)\n",
    "Test [1, 5.000000] training accuracy=0.945000 test accuracy=0.845000 training loss=1.87416e+00, test loss=2.21001e+00 arcitecture_reduction: 5.44080e-01                                                                          \n",
    "Test [1, 10.000000] training accuracy=0.905000 test accuracy=0.845000 training loss=1.83940e+00, test loss=2.13547e+00 arcitecture_reduction: 5.43983e-01 \n",
    "```\n",
    "- Will test cross entropy loss continue to improve?\n",
    "- Can this be repeated with future training and cropping?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5034e5b3",
   "metadata": {},
   "source": [
    "8 January 2022\n",
    "- Training for ~ 200 epochs with droput did not result in a rise in training loss but it did result in a small increase in cross-entropy loss\n",
    "<br /> ![nas_20220107_dropout_00 training weights](../img/nas_20220107_dropout_03_tb.png) <br />\n",
    "- There was only a small decrease in network size.  Cross entropy loss is half the magnitude of architecture loss.\n",
    "<br /> ![nas_20220107_dropout_00 Tensorboard](../img/nas_20220107_dropout_03_cw.png) <br />\n",
    "- I will prune and restart training with 0.1 architecture loss vs the current 0.2.\n",
    "- Will this change the the network pruning?\n",
    "- Will this cause test accuracy to decrease?\n",
    "- Starting nas_20220108_00 with dropout rate of 0.1 and batch norm enabled\n",
    "- Initial network:\n",
    "```cmd\n",
    "+-------------------------------------------+------------+\n",
    "|                  Modules                  | Parameters |\n",
    "+-------------------------------------------+------------+\n",
    "|          cells.0.cell_convolution         |     1      |\n",
    "|         cells.0.cnn.0.conv.weight         |    192     |\n",
    "|          cells.0.cnn.0.conv.bias          |     64     |\n",
    "|      cells.0.cnn.0.batchnorm2d.weight     |     64     |\n",
    "|       cells.0.cnn.0.batchnorm2d.bias      |     64     |\n",
    "|         cells.0.cnn.1.conv.weight         |   36864    |\n",
    "|          cells.0.cnn.1.conv.bias          |     64     |\n",
    "|      cells.0.cnn.1.batchnorm2d.weight     |     64     |\n",
    "|       cells.0.cnn.1.batchnorm2d.bias      |     64     |\n",
    "|         cells.0.cnn.2.conv.weight         |   16384    |\n",
    "|          cells.0.cnn.2.conv.bias          |    256     |\n",
    "|      cells.0.cnn.2.batchnorm2d.weight     |    256     |\n",
    "|       cells.0.cnn.2.batchnorm2d.bias      |    256     |\n",
    "|     cells.0.conv_residual.conv.weight     |    768     |\n",
    "|      cells.0.conv_residual.conv.bias      |    256     |\n",
    "|  cells.0.conv_residual.batchnorm2d.weight |    256     |\n",
    "|   cells.0.conv_residual.batchnorm2d.bias  |    256     |\n",
    "|          cells.1.cell_convolution         |     1      |\n",
    "|         cells.1.cnn.0.conv.weight         |   16384    |\n",
    "|          cells.1.cnn.0.conv.bias          |     64     |\n",
    "|      cells.1.cnn.0.batchnorm2d.weight     |     64     |\n",
    "|       cells.1.cnn.0.batchnorm2d.bias      |     64     |\n",
    "|         cells.1.cnn.1.conv.weight         |   36864    |\n",
    "|          cells.1.cnn.1.conv.bias          |     64     |\n",
    "|      cells.1.cnn.1.batchnorm2d.weight     |     64     |\n",
    "|       cells.1.cnn.1.batchnorm2d.bias      |     64     |\n",
    "|         cells.1.cnn.2.conv.weight         |   16384    |\n",
    "|          cells.1.cnn.2.conv.bias          |    256     |\n",
    "|      cells.1.cnn.2.batchnorm2d.weight     |    256     |\n",
    "|       cells.1.cnn.2.batchnorm2d.bias      |    256     |\n",
    "|     cells.1.conv_residual.conv.weight     |   65536    |\n",
    "|      cells.1.conv_residual.conv.bias      |    256     |\n",
    "|  cells.1.conv_residual.batchnorm2d.weight |    256     |\n",
    "|   cells.1.conv_residual.batchnorm2d.bias  |    256     |\n",
    "|          cells.2.cell_convolution         |     1      |\n",
    "|         cells.2.cnn.0.conv.weight         |   16384    |\n",
    "|          cells.2.cnn.0.conv.bias          |     64     |\n",
    "|      cells.2.cnn.0.batchnorm2d.weight     |     64     |\n",
    "|       cells.2.cnn.0.batchnorm2d.bias      |     64     |\n",
    "|         cells.2.cnn.1.conv.weight         |   36864    |\n",
    "|          cells.2.cnn.1.conv.bias          |     64     |\n",
    "|      cells.2.cnn.1.batchnorm2d.weight     |     64     |\n",
    "|       cells.2.cnn.1.batchnorm2d.bias      |     64     |\n",
    "|         cells.2.cnn.2.conv.weight         |   16384    |\n",
    "|          cells.2.cnn.2.conv.bias          |    256     |\n",
    "|      cells.2.cnn.2.batchnorm2d.weight     |    256     |\n",
    "|       cells.2.cnn.2.batchnorm2d.bias      |    256     |\n",
    "|     cells.2.conv_residual.conv.weight     |   65536    |\n",
    "|      cells.2.conv_residual.conv.bias      |    256     |\n",
    "|  cells.2.conv_residual.batchnorm2d.weight |    256     |\n",
    "|   cells.2.conv_residual.batchnorm2d.bias  |    256     |\n",
    "|          cells.3.cell_convolution         |     1      |\n",
    "|         cells.3.cnn.0.conv.weight         |   32768    |\n",
    "|          cells.3.cnn.0.conv.bias          |    128     |\n",
    "|      cells.3.cnn.0.batchnorm2d.weight     |    128     |\n",
    "|       cells.3.cnn.0.batchnorm2d.bias      |    128     |\n",
    "|         cells.3.cnn.1.conv.weight         |   147456   |\n",
    "|          cells.3.cnn.1.conv.bias          |    128     |\n",
    "|      cells.3.cnn.1.batchnorm2d.weight     |    128     |\n",
    "|       cells.3.cnn.1.batchnorm2d.bias      |    128     |\n",
    "|         cells.3.cnn.2.conv.weight         |   65536    |\n",
    "|          cells.3.cnn.2.conv.bias          |    512     |\n",
    "|      cells.3.cnn.2.batchnorm2d.weight     |    512     |\n",
    "|       cells.3.cnn.2.batchnorm2d.bias      |    512     |\n",
    "|     cells.3.conv_residual.conv.weight     |   131072   |\n",
    "|      cells.3.conv_residual.conv.bias      |    512     |\n",
    "|  cells.3.conv_residual.batchnorm2d.weight |    512     |\n",
    "|   cells.3.conv_residual.batchnorm2d.bias  |    512     |\n",
    "|          cells.4.cell_convolution         |     1      |\n",
    "|         cells.4.cnn.0.conv.weight         |   65536    |\n",
    "|          cells.4.cnn.0.conv.bias          |    128     |\n",
    "|      cells.4.cnn.0.batchnorm2d.weight     |    128     |\n",
    "|       cells.4.cnn.0.batchnorm2d.bias      |    128     |\n",
    "|         cells.4.cnn.1.conv.weight         |   147456   |\n",
    "|          cells.4.cnn.1.conv.bias          |    128     |\n",
    "|      cells.4.cnn.1.batchnorm2d.weight     |    128     |\n",
    "|       cells.4.cnn.1.batchnorm2d.bias      |    128     |\n",
    "|         cells.4.cnn.2.conv.weight         |   65536    |\n",
    "|          cells.4.cnn.2.conv.bias          |    512     |\n",
    "|      cells.4.cnn.2.batchnorm2d.weight     |    512     |\n",
    "|       cells.4.cnn.2.batchnorm2d.bias      |    512     |\n",
    "|     cells.4.conv_residual.conv.weight     |   262144   |\n",
    "|      cells.4.conv_residual.conv.bias      |    512     |\n",
    "|  cells.4.conv_residual.batchnorm2d.weight |    512     |\n",
    "|   cells.4.conv_residual.batchnorm2d.bias  |    512     |\n",
    "|          cells.5.cell_convolution         |     1      |\n",
    "|         cells.5.cnn.0.conv.weight         |   65536    |\n",
    "|          cells.5.cnn.0.conv.bias          |    128     |\n",
    "|      cells.5.cnn.0.batchnorm2d.weight     |    128     |\n",
    "|       cells.5.cnn.0.batchnorm2d.bias      |    128     |\n",
    "|         cells.5.cnn.1.conv.weight         |   147456   |\n",
    "|          cells.5.cnn.1.conv.bias          |    128     |\n",
    "|      cells.5.cnn.1.batchnorm2d.weight     |    128     |\n",
    "|       cells.5.cnn.1.batchnorm2d.bias      |    128     |\n",
    "|         cells.5.cnn.2.conv.weight         |   65536    |\n",
    "|          cells.5.cnn.2.conv.bias          |    512     |\n",
    "|      cells.5.cnn.2.batchnorm2d.weight     |    512     |\n",
    "|       cells.5.cnn.2.batchnorm2d.bias      |    512     |\n",
    "|     cells.5.conv_residual.conv.weight     |   262144   |\n",
    "|      cells.5.conv_residual.conv.bias      |    512     |\n",
    "|  cells.5.conv_residual.batchnorm2d.weight |    512     |\n",
    "|   cells.5.conv_residual.batchnorm2d.bias  |    512     |\n",
    "|          cells.6.cell_convolution         |     1      |\n",
    "|         cells.6.cnn.0.conv.weight         |   65536    |\n",
    "|          cells.6.cnn.0.conv.bias          |    128     |\n",
    "|      cells.6.cnn.0.batchnorm2d.weight     |    128     |\n",
    "|       cells.6.cnn.0.batchnorm2d.bias      |    128     |\n",
    "|         cells.6.cnn.1.conv.weight         |   147456   |\n",
    "|          cells.6.cnn.1.conv.bias          |    128     |\n",
    "|      cells.6.cnn.1.batchnorm2d.weight     |    128     |\n",
    "|       cells.6.cnn.1.batchnorm2d.bias      |    128     |\n",
    "|         cells.6.cnn.2.conv.weight         |   65536    |\n",
    "|          cells.6.cnn.2.conv.bias          |    512     |\n",
    "|      cells.6.cnn.2.batchnorm2d.weight     |    512     |\n",
    "|       cells.6.cnn.2.batchnorm2d.bias      |    512     |\n",
    "|     cells.6.conv_residual.conv.weight     |   262144   |\n",
    "|      cells.6.conv_residual.conv.bias      |    512     |\n",
    "|  cells.6.conv_residual.batchnorm2d.weight |    512     |\n",
    "|   cells.6.conv_residual.batchnorm2d.bias  |    512     |\n",
    "|          cells.7.cell_convolution         |     1      |\n",
    "|         cells.7.cnn.0.conv.weight         |   131072   |\n",
    "|          cells.7.cnn.0.conv.bias          |    256     |\n",
    "|      cells.7.cnn.0.batchnorm2d.weight     |    256     |\n",
    "|       cells.7.cnn.0.batchnorm2d.bias      |    256     |\n",
    "|         cells.7.cnn.1.conv.weight         |   589824   |\n",
    "|          cells.7.cnn.1.conv.bias          |    256     |\n",
    "|      cells.7.cnn.1.batchnorm2d.weight     |    256     |\n",
    "|       cells.7.cnn.1.batchnorm2d.bias      |    256     |\n",
    "|         cells.7.cnn.2.conv.weight         |   262144   |\n",
    "|          cells.7.cnn.2.conv.bias          |    1024    |\n",
    "|      cells.7.cnn.2.batchnorm2d.weight     |    1024    |\n",
    "|       cells.7.cnn.2.batchnorm2d.bias      |    1024    |\n",
    "|     cells.7.conv_residual.conv.weight     |   524288   |\n",
    "|      cells.7.conv_residual.conv.bias      |    1024    |\n",
    "|  cells.7.conv_residual.batchnorm2d.weight |    1024    |\n",
    "|   cells.7.conv_residual.batchnorm2d.bias  |    1024    |\n",
    "|          cells.8.cell_convolution         |     1      |\n",
    "|         cells.8.cnn.0.conv.weight         |   262144   |\n",
    "|          cells.8.cnn.0.conv.bias          |    256     |\n",
    "|      cells.8.cnn.0.batchnorm2d.weight     |    256     |\n",
    "|       cells.8.cnn.0.batchnorm2d.bias      |    256     |\n",
    "|         cells.8.cnn.1.conv.weight         |   589824   |\n",
    "|          cells.8.cnn.1.conv.bias          |    256     |\n",
    "|      cells.8.cnn.1.batchnorm2d.weight     |    256     |\n",
    "|       cells.8.cnn.1.batchnorm2d.bias      |    256     |\n",
    "|         cells.8.cnn.2.conv.weight         |   262144   |\n",
    "|          cells.8.cnn.2.conv.bias          |    1024    |\n",
    "|      cells.8.cnn.2.batchnorm2d.weight     |    1024    |\n",
    "|       cells.8.cnn.2.batchnorm2d.bias      |    1024    |\n",
    "|     cells.8.conv_residual.conv.weight     |  1048576   |\n",
    "|      cells.8.conv_residual.conv.bias      |    1024    |\n",
    "|  cells.8.conv_residual.batchnorm2d.weight |    1024    |\n",
    "|   cells.8.conv_residual.batchnorm2d.bias  |    1024    |\n",
    "|          cells.9.cell_convolution         |     1      |\n",
    "|         cells.9.cnn.0.conv.weight         |   262144   |\n",
    "|          cells.9.cnn.0.conv.bias          |    256     |\n",
    "|      cells.9.cnn.0.batchnorm2d.weight     |    256     |\n",
    "|       cells.9.cnn.0.batchnorm2d.bias      |    256     |\n",
    "|         cells.9.cnn.1.conv.weight         |   589824   |\n",
    "|          cells.9.cnn.1.conv.bias          |    256     |\n",
    "|      cells.9.cnn.1.batchnorm2d.weight     |    256     |\n",
    "|       cells.9.cnn.1.batchnorm2d.bias      |    256     |\n",
    "|         cells.9.cnn.2.conv.weight         |   262144   |\n",
    "|          cells.9.cnn.2.conv.bias          |    1024    |\n",
    "|      cells.9.cnn.2.batchnorm2d.weight     |    1024    |\n",
    "|       cells.9.cnn.2.batchnorm2d.bias      |    1024    |\n",
    "|     cells.9.conv_residual.conv.weight     |  1048576   |\n",
    "|      cells.9.conv_residual.conv.bias      |    1024    |\n",
    "|  cells.9.conv_residual.batchnorm2d.weight |    1024    |\n",
    "|   cells.9.conv_residual.batchnorm2d.bias  |    1024    |\n",
    "|         cells.10.cell_convolution         |     1      |\n",
    "|         cells.10.cnn.0.conv.weight        |   262144   |\n",
    "|          cells.10.cnn.0.conv.bias         |    256     |\n",
    "|     cells.10.cnn.0.batchnorm2d.weight     |    256     |\n",
    "|      cells.10.cnn.0.batchnorm2d.bias      |    256     |\n",
    "|         cells.10.cnn.1.conv.weight        |   589824   |\n",
    "|          cells.10.cnn.1.conv.bias         |    256     |\n",
    "|     cells.10.cnn.1.batchnorm2d.weight     |    256     |\n",
    "|      cells.10.cnn.1.batchnorm2d.bias      |    256     |\n",
    "|         cells.10.cnn.2.conv.weight        |   262144   |\n",
    "|          cells.10.cnn.2.conv.bias         |    1024    |\n",
    "|     cells.10.cnn.2.batchnorm2d.weight     |    1024    |\n",
    "|      cells.10.cnn.2.batchnorm2d.bias      |    1024    |\n",
    "|     cells.10.conv_residual.conv.weight    |  1048576   |\n",
    "|      cells.10.conv_residual.conv.bias     |    1024    |\n",
    "| cells.10.conv_residual.batchnorm2d.weight |    1024    |\n",
    "|  cells.10.conv_residual.batchnorm2d.bias  |    1024    |\n",
    "|         cells.11.cell_convolution         |     1      |\n",
    "|         cells.11.cnn.0.conv.weight        |   262144   |\n",
    "|          cells.11.cnn.0.conv.bias         |    256     |\n",
    "|     cells.11.cnn.0.batchnorm2d.weight     |    256     |\n",
    "|      cells.11.cnn.0.batchnorm2d.bias      |    256     |\n",
    "|         cells.11.cnn.1.conv.weight        |   589824   |\n",
    "|          cells.11.cnn.1.conv.bias         |    256     |\n",
    "|     cells.11.cnn.1.batchnorm2d.weight     |    256     |\n",
    "|      cells.11.cnn.1.batchnorm2d.bias      |    256     |\n",
    "|         cells.11.cnn.2.conv.weight        |   262144   |\n",
    "|          cells.11.cnn.2.conv.bias         |    1024    |\n",
    "|     cells.11.cnn.2.batchnorm2d.weight     |    1024    |\n",
    "|      cells.11.cnn.2.batchnorm2d.bias      |    1024    |\n",
    "|     cells.11.conv_residual.conv.weight    |  1048576   |\n",
    "|      cells.11.conv_residual.conv.bias     |    1024    |\n",
    "| cells.11.conv_residual.batchnorm2d.weight |    1024    |\n",
    "|  cells.11.conv_residual.batchnorm2d.bias  |    1024    |\n",
    "|         cells.12.cell_convolution         |     1      |\n",
    "|         cells.12.cnn.0.conv.weight        |   262144   |\n",
    "|          cells.12.cnn.0.conv.bias         |    256     |\n",
    "|     cells.12.cnn.0.batchnorm2d.weight     |    256     |\n",
    "|      cells.12.cnn.0.batchnorm2d.bias      |    256     |\n",
    "|         cells.12.cnn.1.conv.weight        |   589824   |\n",
    "|          cells.12.cnn.1.conv.bias         |    256     |\n",
    "|     cells.12.cnn.1.batchnorm2d.weight     |    256     |\n",
    "|      cells.12.cnn.1.batchnorm2d.bias      |    256     |\n",
    "|         cells.12.cnn.2.conv.weight        |   262144   |\n",
    "|          cells.12.cnn.2.conv.bias         |    1024    |\n",
    "|     cells.12.cnn.2.batchnorm2d.weight     |    1024    |\n",
    "|      cells.12.cnn.2.batchnorm2d.bias      |    1024    |\n",
    "|     cells.12.conv_residual.conv.weight    |  1048576   |\n",
    "|      cells.12.conv_residual.conv.bias     |    1024    |\n",
    "| cells.12.conv_residual.batchnorm2d.weight |    1024    |\n",
    "|  cells.12.conv_residual.batchnorm2d.bias  |    1024    |\n",
    "|         cells.13.cell_convolution         |     1      |\n",
    "|         cells.13.cnn.0.conv.weight        |   524288   |\n",
    "|          cells.13.cnn.0.conv.bias         |    512     |\n",
    "|     cells.13.cnn.0.batchnorm2d.weight     |    512     |\n",
    "|      cells.13.cnn.0.batchnorm2d.bias      |    512     |\n",
    "|         cells.13.cnn.1.conv.weight        |  2359296   |\n",
    "|          cells.13.cnn.1.conv.bias         |    512     |\n",
    "|     cells.13.cnn.1.batchnorm2d.weight     |    512     |\n",
    "|      cells.13.cnn.1.batchnorm2d.bias      |    512     |\n",
    "|         cells.13.cnn.2.conv.weight        |  1048576   |\n",
    "|          cells.13.cnn.2.conv.bias         |    2048    |\n",
    "|     cells.13.cnn.2.batchnorm2d.weight     |    2048    |\n",
    "|      cells.13.cnn.2.batchnorm2d.bias      |    2048    |\n",
    "|     cells.13.conv_residual.conv.weight    |  2097152   |\n",
    "|      cells.13.conv_residual.conv.bias     |    2048    |\n",
    "| cells.13.conv_residual.batchnorm2d.weight |    2048    |\n",
    "|  cells.13.conv_residual.batchnorm2d.bias  |    2048    |\n",
    "|         cells.14.cell_convolution         |     1      |\n",
    "|         cells.14.cnn.0.conv.weight        |  1048576   |\n",
    "|          cells.14.cnn.0.conv.bias         |    512     |\n",
    "|     cells.14.cnn.0.batchnorm2d.weight     |    512     |\n",
    "|      cells.14.cnn.0.batchnorm2d.bias      |    512     |\n",
    "|         cells.14.cnn.1.conv.weight        |  2359296   |\n",
    "|          cells.14.cnn.1.conv.bias         |    512     |\n",
    "|     cells.14.cnn.1.batchnorm2d.weight     |    512     |\n",
    "|      cells.14.cnn.1.batchnorm2d.bias      |    512     |\n",
    "|         cells.14.cnn.2.conv.weight        |  1048576   |\n",
    "|          cells.14.cnn.2.conv.bias         |    2048    |\n",
    "|     cells.14.cnn.2.batchnorm2d.weight     |    2048    |\n",
    "|      cells.14.cnn.2.batchnorm2d.bias      |    2048    |\n",
    "|     cells.14.conv_residual.conv.weight    |  4194304   |\n",
    "|      cells.14.conv_residual.conv.bias     |    2048    |\n",
    "| cells.14.conv_residual.batchnorm2d.weight |    2048    |\n",
    "|  cells.14.conv_residual.batchnorm2d.bias  |    2048    |\n",
    "|         cells.15.cell_convolution         |     1      |\n",
    "|         cells.15.cnn.0.conv.weight        |  1048576   |\n",
    "|          cells.15.cnn.0.conv.bias         |    512     |\n",
    "|     cells.15.cnn.0.batchnorm2d.weight     |    512     |\n",
    "|      cells.15.cnn.0.batchnorm2d.bias      |    512     |\n",
    "|         cells.15.cnn.1.conv.weight        |  2359296   |\n",
    "|          cells.15.cnn.1.conv.bias         |    512     |\n",
    "|     cells.15.cnn.1.batchnorm2d.weight     |    512     |\n",
    "|      cells.15.cnn.1.batchnorm2d.bias      |    512     |\n",
    "|         cells.15.cnn.2.conv.weight        |  1048576   |\n",
    "|          cells.15.cnn.2.conv.bias         |    2048    |\n",
    "|     cells.15.cnn.2.batchnorm2d.weight     |    2048    |\n",
    "|      cells.15.cnn.2.batchnorm2d.bias      |    2048    |\n",
    "|     cells.15.conv_residual.conv.weight    |  4194304   |\n",
    "|      cells.15.conv_residual.conv.bias     |    2048    |\n",
    "| cells.15.conv_residual.batchnorm2d.weight |    2048    |\n",
    "|  cells.15.conv_residual.batchnorm2d.bias  |    2048    |\n",
    "|                fc.fc.weight               |   20480    |\n",
    "|                 fc.fc.bias                |     10     |\n",
    "+-------------------------------------------+------------+\n",
    "Total Trainable Params: 38108762\n",
    "Test [1, 5.000000] training accuracy=0.095000 test accuracy=0.100000 training loss=7.45281e+00, test loss=4.40786e+00 arcitecture_reduction: 5.36742e-01 \n",
    "```\n",
    "- At 0.1 dropout probability, cross entropy loss rises after 4000k similar to without dropout\n",
    "- Arcitecture reduction may be more effective at 0.1 dropout probability that 0.2\n",
    "<br /> ![nas_20220107_dropout_00 Tensorboard](../img/nas_20220108_00_tb.png) <br />\n",
    "<br /> ![nas_20220107_dropout_00 cell weights](../img/nas_20220108_00_cw.png) <br />\n",
    "- Try again with 0.3 dropout probability \n",
    "- I think minimizing convolutions is more effective for 3x3 convolutions and less on 1x1 convolutions.  Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b0e34e",
   "metadata": {},
   "source": [
    "10 January 2022\n",
    "- Add a scaler function to enable/disable each feature-space convolution so the size minimization can be performed by minimizing a single value\n",
    "- sigmoid(value)*convolution channel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3438b5b-2a15-4a92-b631-83af29e74147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhXklEQVR4nO3deXxU9b3/8dcnCQmQBMjGThJQFpGdiKh1q1bBWrDXpdBa1xbbW6y9aivWX63X29tr9Vpva23VW1e8grjTisVa1/aqEPbNQNgTtmyE7Ov398dMvGMMZCCTnJnJ+/l45JEz55yZvDkzeXNy5sz5mnMOERGJfDFeBxARkdBQoYuIRAkVuohIlFChi4hECRW6iEiUiPPqB6enp7vs7GyvfryISERatWpVsXMuo61lnhV6dnY2ubm5Xv14EZGIZGa7j7ZMh1xERKKECl1EJEqo0EVEokS7hW5mT5rZITPbeJTlZma/NbN8M1tvZlNCH1NERNoTzB7608CMYyyfCYz0f80D/tDxWCIicrzaLXTn3AdA6TFWmQ0863w+BvqZ2aBQBRQRkeCE4hj6EGBvwO0C/7wvMLN5ZpZrZrlFRUUh+NEiItKiS89Dd849DjwOkJOTo+v2ikjUcs5RUddIcUUdJVX1FFfUUez/fsEp/ZkwtF/If2YoCr0QGBZwe6h/nohIVHHOUVpVz6GKOoor6yiprKe4so5i//cS/3RJpa+86xub23ycjOSEsC30pcB8M1sMnA6UO+f2h+BxRUS6nHOOoso6dhVXs6ukit0lVQHT1VTWNX7hPj1ijbTEBNKT40lLTGDUgGTSk+JJT0ogLeB7RlICKYnx9IjtnDPG2y10M1sEnAekm1kB8HOgB4Bz7lFgGXAJkA9UA9d3SlIRkRBxzlFUUcfOYl9J7wwo7t0lVVTVN322bmyMMSylF1lpiZyWnUpmam8G9u1JWmI86ckJpCcm0KdXHGbm4b/Ip91Cd87NbWe5A34QskQiIiHknGNvaQ2r9pSSu6uMtXsPs7O4iuqA0o6LMYal9iY7rTfThqcyPD2RrLTeZKclMiSlV6ftUYeaZxfnEhHpDHWNTWwsPMLq3WXk7i5l1e7DFFfWAZCUEMekYf2YdlpLaScyPC2Rwf16EhchpX0sKnQRiWjFlXWs2l3mL/AyNhSUU9/kezMyM7U354xMZ0pWClOzUhg1IJnYGO8PjXQWFbqIRAznHPmHKlmxq/SzEt9VUg1AfGwM44b04bqzspmSmcKUrH70T+7pceKupUIXkbBXUFbN62v38dqaQrYdqgQgPSmeKZkpfPP0TKZmpXDq4L707BHrcVJvqdBFJCwdrq7njQ37eX3NPlbs8l195LTsFP7tsnGcMzKdzNTeYXFmSThRoYtI2KhtaOJvWw7x2tpC3ss7REOT4+T+Sfz44tHMmjiYYam9vY4Y1lToIuKppmbHJztKeHVNIX/ZeICKukb6Jydw3ZnZzJ40hFMH99GeeJBU6CLS5ZxzbNp3hNfXFrJ03T4OHqkjKSGOGeMG8vXJQ5g+Ii2qz0bpLCp0EekyFbUNPPfxHl5ZXcC2Q5XExRjnje7Pzy4dzIWnDOj2b2p2lApdRDpdfWMzz3+ym9++k09pVT05WSn84rJxfHX8IFIS472OFzVU6CLSaZxzvLFhPw8sz2N3STVnnpTGnTNPYfzQvl5Hi0oqdBHpFB9tL+G+N7ewrqCcMQOTefr60zh3VIbe4OxEKnQRCam8AxXc9+YW3s0rYlDfnvznlRP5+uQhepOzC6jQRSQk9pfX8Ou3tvLy6gISE+JYMHMM152ZrTc6u5AKXUQ6pLymgUff386Tf9+Jc3DDWcP5wfkn681OD6jQReSE1DU28dzHe3j4nW0crm7gskmDue2i0fo0p4dU6CJyXJqbHX9av48HludRUFbD2SPTuWPGGMYN0ZkrXlOhi0jQ8g9V8i8vrGVDYTmnDOrDszeM55xRGV7HEj8VuogE5a1NB7h1yToS4mJ46BsTmT1xCDE6cyWsqNBF5Jiamh3/9fZWHn4nnwlD+/Lo1VMZ3K+X17GkDSp0ETmq8uoGbnlhDe/lFXFVzlDunT1OpyGGMRW6iLQp70AF8xbmsu9wDb+4bBzfOj1Tn/IMcyp0EfmCP6/fx49fXE9SzzgWz5vO1KxUryNJEFToIvKZxqZmHliex2Mf7GBqVgp/+NYU+vfpXgMtRzIVuogAUFpVz82LVvOP/BK+PT2Ln106lvi4GK9jyXFQoYsIGwvLuWnhKooq67j/iglclTPM60hyAlToIt3cK6sLuPOVDaQlxvPiTWcwcVg/ryPJCVKhi3RTDU3N/PsbW3j6f3cxfUQqv/vmFNKTEryOJR2gQhfphooq6vjB86tZsbOUG780nDtnjiEuVsfLI50KXaSbWbOnjO8/t5rDNfX8Zs4kZk8a4nUkCREVukg38l7eIeY9u4oBfRN45ftnMXZwH68jSQgF9TeWmc0wszwzyzezBW0szzSzd81sjZmtN7NLQh9VRDpi1e4yvvfcKk7un8TSH3xJZR6F2i10M4sFHgFmAmOBuWY2ttVq/w9Y4pybDMwBfh/qoCJy4vIOVHDD0ysZ2Kcnz9wwTaMJRalg9tCnAfnOuR3OuXpgMTC71ToOaPnvvi+wL3QRRaQj9pZWc82Tn5AQF8PCG08nI1lnskSrYAp9CLA34HaBf16ge4CrzawAWAbc3NYDmdk8M8s1s9yioqITiCsix6Oooo5vP/EJNfVNLLzxdA0PF+VCdZ7SXOBp59xQ4BJgoZl94bGdc48753KcczkZGRrlRKQzHalt4LqnVnDgSC1PXX8aowcmex1JOlkwhV4IBH4OeKh/XqAbgSUAzrmPgJ5AeigCisjxq21o4rvP5JJ3oII/XD1VV0vsJoIp9JXASDMbbmbx+N70XNpqnT3ABQBmdgq+QtcxFREPNDY1c/OiNazYVcqDV03k/NH9vY4kXaTdQnfONQLzgeXAFnxns2wys3vNbJZ/tduA75rZOmARcJ1zznVWaBFpm3OOO1/ZwF83H+Ser52qDw11M0F9sMg5twzfm52B8+4OmN4MnBXaaCJyvO5781NeXFXALReM5Nozs72OI11MF28QiRKPvr+dxz7YwTVnZPGjC0d6HUc8oEIXiQJLVu7lvjc/5WsTB3PP107V2J/dlApdJMIt33SABa+s55xRGTx45URiYlTm3ZUKXSSCfbS9hJsXrWHisH48evUUDRnXzenZF4lQGwvL+e6zuWSn9eap606jd7wuntrdqdBFItCOokqufXIFfXv14NkbTqdfb11sS1ToIhHnQHkt335iBQALb5zGwL49PU4k4UJ/o4lEkPKaBq558hPKaxpYPG86IzKSvI4kYUR76CIRwjnHT1/ZwI6iKh6/ZirjhvT1OpKEGRW6SIRYtGIvb2zYz+0Xj+bMk3TtO/kiFbpIBMg7UMG//mkTZ49MZ97ZI7yOI2FKhS4S5mrqm7h50WqSe/bg11dN0geH5Kj0pqhImLv3z5vZerCShTdO0/BxckzaQxcJY2+s38+iFXv43rkncfZIjfIlx6ZCFwlTe0urWfDKeiYN68dtF43yOo5EABW6SBhq8I86hIOH506mR6x+VaV9OoYuEoYefGsra/ce5pFvTmFYam+v40iE0H/7ImHmg61FPPr+duZOy+SrEwZ5HUciiApdJIwcqqjl1iVrGTUgibsvHet1HIkwOuQiEiaamx23LVlHRW0j//Od6fSKj/U6kkQY7aGLhInHP9zBh9uK+fnXTmX0wGSv40gEUqGLhIHVe8r4z+V5fHX8IOZOG+Z1HIlQKnQRj5XXNPDDRWsY0Kcnv/yn8RrgWU6YjqGLeKjlkrj7y2tZctMZ9O3Vw+tIEsG0hy7iocUrfZfEve2iUUzNSvE6jkQ4FbqIR7Ye9F0S90snp/O9c07yOo5EARW6iAdqG5qY//xqkhLi+PU3JuqSuBISOoYu4oGWS+I+c8M0+idrkGcJDe2hi3SxZRv28/wne7jp3BGcO0qXxJXQUaGLdKHCwzXc8fJ6Jg7rx+0XjfY6jkQZFbpIF2k5RbGp2fHwHF0SV0IvqFeUmc0wszwzyzezBUdZ5yoz22xmm8zs+dDGFIl8r6wu5P2tRfzk4tFkpumSuBJ67b4pamaxwCPAV4ACYKWZLXXObQ5YZyRwJ3CWc67MzPp3VmCRSFRUUce9f97M1KwUrjkj2+s4EqWC2UOfBuQ753Y45+qBxcDsVut8F3jEOVcG4Jw7FNqYIpHtnqWbqKlv4leXT9ApitJpgin0IcDegNsF/nmBRgGjzOwfZvaxmc0IVUCRSPeXjQd4Y8N+brlwJCf3T/I6jkSxUJ2HHgeMBM4DhgIfmNl459zhwJXMbB4wDyAzMzNEP1okfJVXN/Cz1zcydlAf5p0zwus4EuWC2UMvBAKv5znUPy9QAbDUOdfgnNsJbMVX8J/jnHvcOZfjnMvJyND5txL9fvHGZkqr6rn/igk6q0U6XTCvsJXASDMbbmbxwBxgaat1XsO3d46ZpeM7BLMjdDFFIs+H24p4cVUB884Zwbghfb2OI91Au4XunGsE5gPLgS3AEufcJjO718xm+VdbDpSY2WbgXeDHzrmSzgotEu6q6hpZ8PIGRqQncssFX/hjVaRTBHUM3Tm3DFjWat7dAdMOuNX/JdLtPbA8j33lNSy56Qx69tDYoNI1dFBPJMRW7S7lmY92cc30LE7LTvU6jnQjKnSREKptaOInL61ncN9e/HjGGK/jSDejy+eKhNDv3slne1EVz9wwjaQE/XpJ19IeukiIbNpXzh/e387lU4bqsrjiCRW6SAg0NjXzk5fWk9I7np9deorXcaSb0t+EIiHw3x/uZNO+I/zhW1Po1zve6zjSTWkPXaSDthdV8tDbW5lx6kBmjh/kdRzpxlToIh3Q3OxY8PJ6esbFcO/sU72OI92cCl2kA577ZDcrd5Xxs0vH0r+PBnsWb6nQRU5QQVk1v3rzU84emc4VU4d6HUdEhS5yIpxz/PTVjTjgl18fj5kGrRDvqdBFTsArqwv5wD8+6LBUjQ8q4UGFLnKcWsYHzdH4oBJmVOgix+nnSzdSU9/EfRofVMKMCl3kOPxl4wGWbTig8UElLKnQRYKk8UEl3Omj/yJBahkf9KnrTtP4oBKW9KoUCcIHW33jg96k8UEljKnQRdpRVdfIna/4xgf9ocYHlTCmQy4i7dD4oBIptIcucgy5uzQ+qEQOFbrIUdQ2NHHHyxofVCKHDrmIHMXD72zT+KASUbSHLtKGTfvKefT9HRofVCKKCl2kFY0PKpFKf0eKtPL4hzs0PqhEJO2hiwTYXlTJf729TeODSkRSoYv4fW580Ms0PqhEHhW6iN/nxgdN1vigEnlU6CJofFCJDip06fY0PqhECxW6dHst44PeMWOMxgeViBZUoZvZDDPLM7N8M1twjPUuNzNnZjmhiyjSeQ5V1H42Pui3p2d5HUekQ9otdDOLBR4BZgJjgblmNraN9ZKBW4BPQh1SpLPcs3QTNQ0aH1SiQzB76NOAfOfcDudcPbAYmN3Gev8G/AqoDWE+kU7zl437feODXqDxQSU6BFPoQ4C9AbcL/PM+Y2ZTgGHOuTeO9UBmNs/Mcs0st6io6LjDioRKeXUD/++1TRofVKJKh98UNbMY4NfAbe2t65x73DmX45zLycjQBY/EO794YzNl1fXcf8UEjQ8qUSOYV3IhMCzg9lD/vBbJwDjgPTPbBUwHluqNUQlXGh9UolUwhb4SGGlmw80sHpgDLG1Z6Jwrd86lO+eynXPZwMfALOdcbqckFumAz8YHzdD4oBJ92i1051wjMB9YDmwBljjnNpnZvWY2q7MDioTSz5duYl95Db+6fILGB5WoE9Tlc51zy4BlrebdfZR1z+t4LJHQe21NIS+tKuCHXz5Z44NKVNK7QdIt7Cqu4q5XN3BadooOtUjUUqFL1KtrbGL+otXExcbwmzmTidNZLRKlNGKRRL37/5LHxsIjPPbtqQzu18vrOCKdRrsqEtXe+fQgT/x9J9eekcXFpw70Oo5Ip1KhS9Q6eKSW219czymD+nDnJRrsWaKfCl2iUlOz40eL11JT38TDcyfrFEXpFnQMXaLS79/N56MdJTxwxQRdeEu6De2hS9RZuauUh97eyuxJgzWcnHQrKnSJKoer67ll0RqGpfbmF5eN03By0q3okItEDeccP3lpPUWVdbz8/TNJ7tnD60giXUp76BI1Fn68m7c2H+SOGWOYMLSf13FEupwKXaLC5n1H+MUbWzh/dAY3nDXc6zginlChS8Srrm9k/qLV9OvVg/+8cqLGBpVuS8fQJeLds3QTO4ur+J/vnE5aUoLXcUQ8oz10iWivry1kSW4B888/mTNPSvc6joinVOgSsXaXVHHXqxvJyUrhFl0SV0SFLpGpvrGZmxetITbG+M1cXRJXBHQMXSLUA8s/ZX1BOY9ePZUhuiSuCKA9dIlA7+Yd4r8/3Mk1Z2QxY5wuiSvSQoUuEWV/eQ23L1nHmIHJ/FSXxBX5HBW6RIyyqnqueWIFdY3N/O6bU3RJXJFWdAxdIkJVXSPXP72S3aXVPHP9NF0SV6QN2kOXsFff2Mz3nlvF+oLDPDx3MmeclOZ1JJGwpD10CWtNzY5bl6zlw23F3H/5BI0LKnIM2kOXsOWc456lm/jz+v3cOXMMV502zOtIImFNhS5h66G3t7Hw493cdM4Ibjr3JK/jiIQ9FbqEpaf/sZPf/m0bV+UMZcHMMV7HEYkIKnQJO6+vLeSeP23morED+OXXx2sYOZEgqdAlrLybd4jblqzj9OGp/FbXaBE5LvptkbCxancp339uFaMHJvPHa3P0wSGR46RCl7Dw6YEjXP/USgb17cUzN0zTAM8iJyCoQjezGWaWZ2b5ZragjeW3mtlmM1tvZn8zs6zQR5Votbe0mmueWEGv+FievWEa6Rp1SOSEtFvoZhYLPALMBMYCc81sbKvV1gA5zrkJwEvA/aEOKtGpqKKOq5/4hLrGZp694XSGpfb2OpJIxApmD30akO+c2+GcqwcWA7MDV3DOveucq/bf/BgYGtqYEo2O1DZw7ZMrOHSkjievO43RA5O9jiQS0YIp9CHA3oDbBf55R3Mj8GZbC8xsnpnlmlluUVFR8Ckl6tQ2NPGdZ3LZerCCP1w9halZKV5HEol4IX1T1MyuBnKAB9pa7px73DmX45zLycjICOWPlgjS2NTM/OfXsHJXKQ9eNZHzRvf3OpJIVAjm4lyFQOBFNIb6532OmV0I3AWc65yrC008iTbNzY47Xt7A21sOcu/sU5k96Vh/7InI8QhmD30lMNLMhptZPDAHWBq4gplNBh4DZjnnDoU+pkSDyrpG5i9azcurC/jRhSO55oxsryOJRJV299Cdc41mNh9YDsQCTzrnNpnZvUCuc24pvkMsScCL/o9p73HOzerE3BJhdhZXMe/ZXLYXVfLTS8bw3bNHeB1JJOoEdT1059wyYFmreXcHTF8Y4lwSRf625SA/emEtcTHGwhtP56yT072OJBKVNMCFdJrmZsdv39nGf729jVMH9+Gxb09laIrOMxfpLCp06RRHahu49YW1vL3lEP80ZQi//Pp4XZtFpJOp0CXkth2s4KaFq9hTWs2/zjqVa87I0iVwRbqACl1C6s0N+7n9xXX0io/l+e9OZ9rwVK8jiXQbKnQJiaZmx4Nv5fH797YzaVg/Hr16KgP79vQ6lki3okKXDjtcXc8PF6/lg61FzJ2WyT2zxpIQp+PlIl1NhS4dsnnfEW56LpeD5XX8xz+NZ+60TK8jiXRbKnQ5Ya+vLeSOl9fTr1c8i2+azpRMXWBLxEsqdDlujU3N3Pfmp/zx7zuZlp3KI9+aQkayBqUQ8ZoKXY5L4eEabl+yjo92lHDdmdnc9dVT6KGBnEXCggpdglJe3cAj7+Xz9P/uwoAHr5zI5VM1jolIOFGhyzHVNjTx7Ee7+N07+VTUNXL5lKHc+pVRDO7Xy+toItKKCl3a1NzseG1tIQ++tZXCwzWcNzqDO2aM4ZRBfbyOJiJHoUKXL/hgaxH/8eanbNl/hPFD+vLAFRM4U1dIFAl7KnT5zMbCcu5781P+nl/MsNRe/HbuZC4dP4iYGF2HRSQSqNCFvaXVPPhWHq+t3UdK7x7cfelYvjU9U5/2FIkwKvRurKyqnkfezefZj3YTEwP/fN5JfO+8k+jTs4fX0UTkBKjQu6Hahiae+scufv9ePlV1jVw5dRj/8pVRupiWSIRToXcje0ureW1NIc+v2MP+8louGNOfO2aOYdSAZK+jiUgIqNCjXGlVPW9s2M9rawpZtbsMgOkjUnnoG5OYPiLN43QiEkoq9ChUU9/E21sO8tqaQt7fWkRjs2P0gGTumDGGWZMGM0QfChKJSir0KNHU7Pjf7cW8tmYff9m4n6r6Jgb26cmNXxrOZZOH6ANBIt2ACj2COefYtO8Ir64p5E/r9nGooo7khDgunTCY2ZMHc/rwNGJ1DrlIt6FCj0B7S6t5fW0hr64pZHtRFfGxMZw/JoPLJg3h/DH96dlD54+LdEcq9DDX3OzYdqiSVbvLWLW7jNV7ythZXAXAtOGpfOfsEVwybhB9e+vccZHuToUeZirrGlm39/DnCryithGA9KR4pmSm8M1pmcwcP5ChKb09Tisi4USF7iHnHAVlNaze4yvv3F1lfHrgCM0OzGD0gGS+NnEwUzNTyMlOITO1N2Y6Ji4ibVOhd5HGpmb2Ha5lZ0kV2w5WfLYHfqiiDoDE+FgmZ6Yw/8sjmZqVwuTMfvoIvogcFxV6CDU2NVN4uIadxVXsLqn2f/dN7y2rpqHJfbbu0JRenHlSGlOzUpiSlcKYgX10RoqIdIgK/TjV1Ddx8Egtu0qq2FVcxa6Sana1lHZpNY3N/1faveNjyUpLZMygZC4eN5DhaYlkpfVmREaSBlUWkZDr9oXunKO8poHiyjqKK+sprqyjxP/9/277pksq66iqb/rc/RP9pT12UB9mjhtIdnoi2WmJZKf1JiM5Qce8RaTLBFXoZjYD+A0QC/zROXdfq+UJwLPAVKAE+IZzbldoo7atqdlRWdfo+6ptpLKugYraRqrqmj6bbllWVd9IRW0jR2obKa6oo6TKV96Be9UtYgxSE+NJT0ogLSmeyZn9SEtMID05noykBLLTfXvbGUkqbREJD+0WupnFAo8AXwEKgJVmttQ5tzlgtRuBMufcyWY2B/gV8I3OCPzCyj089v4OKvwlXdPQ1P6d8B3+SEqIIykhjuSecQzq25NxQ/r4CzuB9CRfebcUeErveB3TFpGIEswe+jQg3zm3A8DMFgOzgcBCnw3c459+CfidmZlz7ou7vh2UmpjA2MF9SO4Z5y/oHiQmxPpv9yCp5/+VdqK/wBPjY4mLjQl1FBGRsBJMoQ8B9gbcLgBOP9o6zrlGMysH0oDiwJXMbB4wDyAzM/OEAn9l7AC+MnbACd1XRCSadeluq3PucedcjnMuJyMjoyt/tIhI1Aum0AuBYQG3h/rntbmOmcUBffG9OSoiIl0kmEJfCYw0s+FmFg/MAZa2WmcpcK1/+grgnc44fi4iIkfX7jF0/zHx+cByfKctPumc22Rm9wK5zrmlwBPAQjPLB0rxlb6IiHShoM5Dd84tA5a1mnd3wHQtcGVoo4mIyPHQuXwiIlFChS4iEiVU6CIiUcK8OhnFzIqA3Sd493RafWgpzChfxyhfx4V7RuU7cVnOuTY/yONZoXeEmeU653K8znE0ytcxytdx4Z5R+TqHDrmIiEQJFbqISJSI1EJ/3OsA7VC+jlG+jgv3jMrXCSLyGLqIiHxRpO6hi4hIKyp0EZEoEbaFbmZXmtkmM2s2s6OePmRmM8wsz8zyzWxBwPzhZvaJf/4L/itFhjJfqpn91cy2+b+ntLHO+Wa2NuCr1swu8y972sx2Biyb1NX5/Os1BWRYGjA/HLbfJDP7yP86WG9m3whY1inb72ivp4DlCf7tke/fPtkBy+70z88zs4tDkecE8t1qZpv92+tvZpYVsKzN57qL811nZkUBOb4TsOxa/+thm5ld2/q+XZTvoYBsW83scMCyTt9+HeacC8sv4BRgNPAekHOUdWKB7cAIIB5YB4z1L1sCzPFPPwp8P8T57gcW+KcXAL9qZ/1UfFei7O2//TRwRSduv6DyAZVHme/59gNGASP904OB/UC/ztp+x3o9Bazzz8Cj/uk5wAv+6bH+9ROA4f7HifUg3/kBr7Hvt+Q71nPdxfmuA37Xxn1TgR3+7yn+6ZSuztdq/ZvxXV22S7ZfKL7Cdg/dObfFOZfXzmqfjXfqnKsHFgOzzcyAL+Mb3xTgGeCyEEec7X/cYB//CuBN51x1iHMczfHm+0y4bD/n3Fbn3Db/9D7gENCZQ121+XpqtU5g7peAC/zbazaw2DlX55zbCeT7H69L8znn3g14jX2Mb0CarhLM9juai4G/OudKnXNlwF+BGR7nmwssCnGGThW2hR6ktsY7HYJvPNPDzrnGVvNDaYBzbr9/+gDQ3kCnc/jii+Pf/X8aP2RmCR7l62lmuWb2ccvhIMJw+5nZNHx7VdsDZod6+x3t9dTmOv7t0zJ+bjD37Yp8gW4E3gy43dZz7UW+y/3P20tm1jIaWlhtP/+hquHAOwGzO3v7dVhQ10PvLGb2NjCwjUV3Oede7+o8rR0rX+AN55wzs6Oe/2lmg4Dx+AYJaXEnviKLx3fO6x3AvR7ky3LOFZrZCOAdM9uAr6Q6LMTbbyFwrXOu2T+7w9svmpnZ1UAOcG7A7C8818657W0/Qqf5E7DIOVdnZjfh+2vny12cIRhzgJecc00B88Jh+x2Tp4XunLuwgw9xtPFOS4B+Zhbn34tqaxzUDuUzs4NmNsg5t99fOIeO8VBXAa865xoCHrtl77TOzJ4Cbvcin3Ou0P99h5m9B0wGXiZMtp+Z9QHewPef/McBj93h7deG4xk/t8A+P35uMPftinyY2YX4/tM81zlX1zL/KM91KAup3XzOucCxhv+I772Ulvue1+q+74UwW1D5AswBfhA4owu2X4dF+iGXNsc7db53MN7Fd9wafOOdhnqPP3Ac1fYe/wvH4vwl1nK8+jJgY1fnM7OUlkMVZpYOnAVsDpft539OXwWedc691GpZZ2y/joyfuxSY4z8LZjgwElgRgkzHlc/MJgOPAbOcc4cC5rf5XHuQb1DAzVnAFv/0cuAif84U4CI+/xdtl+TzZxyD743ZjwLmdcX26ziv35U92hfwdXzHuOqAg8By//zBwLKA9S4BtuL7n/KugPkj8P1C5QMvAgkhzpcG/A3YBrwNpPrn5wB/DFgvG99eQEyr+78DbMBXRM8BSV2dDzjTn2Gd//uN4bT9gKuBBmBtwNekztx+bb2e8B3KmeWf7unfHvn+7TMi4L53+e+XB8zspN+L9vK97f99adleS9t7rrs4338Am/w53gXGBNz3Bv92zQeu9yKf//Y9wH2t7tcl26+jX/rov4hIlIj0Qy4iIuKnQhcRiRIqdBGRKKFCFxGJEip0EZEooUIXEYkSKnQRkSjx/wHmEA6XzRjJ3QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x, k=5.0):\n",
    "    return 1.0/(1.0+np.exp(-k*x))\n",
    "\n",
    "x = np.arange(-1.0, 1.0, 0.1) \n",
    "y = sigmoid(x) \n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5856527-0a6a-40de-83e4-968062a87ba0",
   "metadata": {},
   "source": [
    "55- Added channel_scale so the convolution can be minimized by searching a single value rather the norm of the convolution\n",
    "- ConvBR::Forward, rather than scaling the convlution weights, I can scale the convolution output of all batches and convolutions by sigmoid(sigmoid_scale*cannel_scale)\n",
    "```python\n",
    "        x = self.conv(x)\n",
    "        if self.search_structure: #scale channels based on \n",
    "            weight_scale = self.sigmoid(self.sigmoid_scale*self.channel_scale)[None,:,None,None]\n",
    "            x *= weight_scale\n",
    "```\n",
    "- CpmvBR::ArchitectureWeights scales the architecture weight convolution norm by (sigmoid_scale*channel_scale):\n",
    "```python\n",
    "        weight_scale = self.sigmoid(self.sigmoid_scale*self.channel_scale)\n",
    "        conv_weights = torch.tanh(self.weight_gain*weight_scale*torch.linalg.norm(self.conv.weight, dim=(1,2,3)))\n",
    "```\n",
    "- sigmoid scale = 5 transitions from ~0 at -1 to ~1 at 1.  Not necessary but it it makes me happy to have the weights normalized in that range\n",
    "- This resulted in a much more agressive pruning\n",
    "<br /> ![nas_20220110_00 cell weights](../img/nas_20220110_00_cw.png) <br />\n",
    "- Accuracy converged well with test tracking training effectively\n",
    "<br /> ![nas_20220110_00 Tensorboard](../img/nas_20220110_00_tb.png) <br />\n",
    "- Pruning was too effective but not reflected in search weight.  Add pruning information to ConvBR::ApplyStructure so the convoluation weight an pruning is clear that results in everything being pruned.\n",
    "- Why didn't the plot show everything was being pruned?  \n",
    "```cmd\n",
    "Total Trainable Params: 38146522\n",
    "ConvBR::ApplyStructure Cell 0 convolution 0/3 1.0=64/64 in_channels=3 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 0 convolution 1/3 1.0=64/64 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 0 convolution 2/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 0 cell residual 1.0=256/256 in_channels=3 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 1 convolution 0/3 1.0=64/64 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 1 convolution 1/3 1.0=64/64 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 1 convolution 2/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 1 cell residual 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 2 convolution 0/3 1.0=64/64 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 2 convolution 1/3 1.0=64/64 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 2 convolution 2/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 2 cell residual 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 3 convolution 0/3 1.0=128/128 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 3 convolution 1/3 1.0=128/128 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 3 convolution 2/3 1.0=512/512 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 3 cell residual 1.0=512/512 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 4 convolution 0/3 1.0=128/128 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 4 convolution 1/3 1.0=128/128 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 4 convolution 2/3 1.0=512/512 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 4 cell residual 1.0=512/512 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 5 convolution 0/3 1.0=128/128 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 5 convolution 1/3 1.0=128/128 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 5 convolution 2/3 1.0=512/512 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 5 cell residual 1.0=512/512 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 6 convolution 0/3 1.0=128/128 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 6 convolution 1/3 1.0=128/128 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 6 convolution 2/3 1.0=512/512 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 6 cell residual 1.0=512/512 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 7 convolution 0/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 7 convolution 1/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 7 convolution 2/3 1.0=1024/1024 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 7 cell residual 1.0=1024/1024 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 8 convolution 0/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 8 convolution 1/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 8 convolution 2/3 1.0=1024/1024 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 8 cell residual 1.0=1024/1024 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 9 convolution 0/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 9 convolution 1/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 9 convolution 2/3 1.0=1024/1024 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 9 cell residual 1.0=1024/1024 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 10 convolution 0/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 10 convolution 1/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 10 convolution 2/3 1.0=1024/1024 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 10 cell residual 1.0=1024/1024 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 11 convolution 0/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 11 convolution 1/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 11 convolution 2/3 1.0=1024/1024 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 11 cell residual 1.0=1024/1024 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 12 convolution 0/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 12 convolution 1/3 1.0=256/256 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 12 convolution 2/3 1.0=1024/1024 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 12 cell residual 1.0=1024/1024 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 13 convolution 0/3 1.0=512/512 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 13 convolution 1/3 1.0=512/512 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 13 convolution 2/3 1.0=2048/2048 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 13 cell residual 1.0=2048/2048 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 14 convolution 0/3 1.0=512/512 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 14 convolution 1/3 1.0=512/512 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 14 convolution 2/3 1.0=2048/2048 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 14 cell residual 1.0=2048/2048 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 15 convolution 0/3 1.0=512/512 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 15 convolution 1/3 1.0=512/512 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 15 convolution 2/3 1.0=2048/2048 in_channels=0 out_channels=0\n",
    "ConvBR::ApplyStructure Cell 15 cell residual 1.0=2048/2048 in_channels=0 out_channels=0\n",
    "FC::ApplyStructure in 1.0=2048/2048 out 0.0=0/10 convolutions in_channels=0 out_channels=10\n",
    "+-------------------------------------------+------------+\n",
    "|                  Modules                  | Parameters |\n",
    "+-------------------------------------------+------------+\n",
    "|          cells.0.cell_convolution         |     1      |\n",
    "|        cells.0.cnn.0.channel_scale        |     64     |\n",
    "|         cells.0.cnn.0.conv.weight         |     0      |\n",
    "|          cells.0.cnn.0.conv.bias          |     0      |\n",
    "|      cells.0.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|       cells.0.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.0.cnn.1.channel_scale        |     64     |\n",
    "|         cells.0.cnn.1.conv.weight         |     0      |\n",
    "|          cells.0.cnn.1.conv.bias          |     0      |\n",
    "|      cells.0.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|       cells.0.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.0.cnn.2.channel_scale        |    256     |\n",
    "|         cells.0.cnn.2.conv.weight         |     0      |\n",
    "|          cells.0.cnn.2.conv.bias          |     0      |\n",
    "|      cells.0.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|       cells.0.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.0.conv_residual.channel_scale    |    256     |\n",
    "|     cells.0.conv_residual.conv.weight     |     0      |\n",
    "|      cells.0.conv_residual.conv.bias      |     0      |\n",
    "|  cells.0.conv_residual.batchnorm2d.weight |     0      |\n",
    "|   cells.0.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|          cells.1.cell_convolution         |     1      |\n",
    "|        cells.1.cnn.0.channel_scale        |     64     |\n",
    "|         cells.1.cnn.0.conv.weight         |     0      |\n",
    "|          cells.1.cnn.0.conv.bias          |     0      |\n",
    "|      cells.1.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|       cells.1.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.1.cnn.1.channel_scale        |     64     |\n",
    "|         cells.1.cnn.1.conv.weight         |     0      |\n",
    "|          cells.1.cnn.1.conv.bias          |     0      |\n",
    "|      cells.1.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|       cells.1.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.1.cnn.2.channel_scale        |    256     |\n",
    "|         cells.1.cnn.2.conv.weight         |     0      |\n",
    "|          cells.1.cnn.2.conv.bias          |     0      |\n",
    "|      cells.1.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|       cells.1.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.1.conv_residual.channel_scale    |    256     |\n",
    "|     cells.1.conv_residual.conv.weight     |     0      |\n",
    "|      cells.1.conv_residual.conv.bias      |     0      |\n",
    "|  cells.1.conv_residual.batchnorm2d.weight |     0      |\n",
    "|   cells.1.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|          cells.2.cell_convolution         |     1      |\n",
    "|        cells.2.cnn.0.channel_scale        |     64     |\n",
    "|         cells.2.cnn.0.conv.weight         |     0      |\n",
    "|          cells.2.cnn.0.conv.bias          |     0      |\n",
    "|      cells.2.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|       cells.2.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.2.cnn.1.channel_scale        |     64     |\n",
    "|         cells.2.cnn.1.conv.weight         |     0      |\n",
    "|          cells.2.cnn.1.conv.bias          |     0      |\n",
    "|      cells.2.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|       cells.2.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.2.cnn.2.channel_scale        |    256     |\n",
    "|         cells.2.cnn.2.conv.weight         |     0      |\n",
    "|          cells.2.cnn.2.conv.bias          |     0      |\n",
    "|      cells.2.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|       cells.2.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.2.conv_residual.channel_scale    |    256     |\n",
    "|     cells.2.conv_residual.conv.weight     |     0      |\n",
    "|      cells.2.conv_residual.conv.bias      |     0      |\n",
    "|  cells.2.conv_residual.batchnorm2d.weight |     0      |\n",
    "|   cells.2.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|          cells.3.cell_convolution         |     1      |\n",
    "|        cells.3.cnn.0.channel_scale        |    128     |\n",
    "|         cells.3.cnn.0.conv.weight         |     0      |\n",
    "|          cells.3.cnn.0.conv.bias          |     0      |\n",
    "|      cells.3.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|       cells.3.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.3.cnn.1.channel_scale        |    128     |\n",
    "|         cells.3.cnn.1.conv.weight         |     0      |\n",
    "|          cells.3.cnn.1.conv.bias          |     0      |\n",
    "|      cells.3.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|       cells.3.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.3.cnn.2.channel_scale        |    512     |\n",
    "|         cells.3.cnn.2.conv.weight         |     0      |\n",
    "|          cells.3.cnn.2.conv.bias          |     0      |\n",
    "|      cells.3.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|       cells.3.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.3.conv_residual.channel_scale    |    512     |\n",
    "|     cells.3.conv_residual.conv.weight     |     0      |\n",
    "|      cells.3.conv_residual.conv.bias      |     0      |\n",
    "|  cells.3.conv_residual.batchnorm2d.weight |     0      |\n",
    "|   cells.3.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|          cells.4.cell_convolution         |     1      |\n",
    "|        cells.4.cnn.0.channel_scale        |    128     |\n",
    "|         cells.4.cnn.0.conv.weight         |     0      |\n",
    "|          cells.4.cnn.0.conv.bias          |     0      |\n",
    "|      cells.4.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|       cells.4.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.4.cnn.1.channel_scale        |    128     |\n",
    "|         cells.4.cnn.1.conv.weight         |     0      |\n",
    "|          cells.4.cnn.1.conv.bias          |     0      |\n",
    "|      cells.4.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|       cells.4.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.4.cnn.2.channel_scale        |    512     |\n",
    "|         cells.4.cnn.2.conv.weight         |     0      |\n",
    "|          cells.4.cnn.2.conv.bias          |     0      |\n",
    "|      cells.4.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|       cells.4.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.4.conv_residual.channel_scale    |    512     |\n",
    "|     cells.4.conv_residual.conv.weight     |     0      |\n",
    "|      cells.4.conv_residual.conv.bias      |     0      |\n",
    "|  cells.4.conv_residual.batchnorm2d.weight |     0      |\n",
    "|   cells.4.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|          cells.5.cell_convolution         |     1      |\n",
    "|        cells.5.cnn.0.channel_scale        |    128     |\n",
    "|         cells.5.cnn.0.conv.weight         |     0      |\n",
    "|          cells.5.cnn.0.conv.bias          |     0      |\n",
    "|      cells.5.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|       cells.5.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.5.cnn.1.channel_scale        |    128     |\n",
    "|         cells.5.cnn.1.conv.weight         |     0      |\n",
    "|          cells.5.cnn.1.conv.bias          |     0      |\n",
    "|      cells.5.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|       cells.5.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.5.cnn.2.channel_scale        |    512     |\n",
    "|         cells.5.cnn.2.conv.weight         |     0      |\n",
    "|          cells.5.cnn.2.conv.bias          |     0      |\n",
    "|      cells.5.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|       cells.5.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.5.conv_residual.channel_scale    |    512     |\n",
    "|     cells.5.conv_residual.conv.weight     |     0      |\n",
    "|      cells.5.conv_residual.conv.bias      |     0      |\n",
    "|  cells.5.conv_residual.batchnorm2d.weight |     0      |\n",
    "|   cells.5.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|          cells.6.cell_convolution         |     1      |\n",
    "|        cells.6.cnn.0.channel_scale        |    128     |\n",
    "|         cells.6.cnn.0.conv.weight         |     0      |\n",
    "|          cells.6.cnn.0.conv.bias          |     0      |\n",
    "|      cells.6.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|       cells.6.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.6.cnn.1.channel_scale        |    128     |\n",
    "|         cells.6.cnn.1.conv.weight         |     0      |\n",
    "|          cells.6.cnn.1.conv.bias          |     0      |\n",
    "|      cells.6.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|       cells.6.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.6.cnn.2.channel_scale        |    512     |\n",
    "|         cells.6.cnn.2.conv.weight         |     0      |\n",
    "|          cells.6.cnn.2.conv.bias          |     0      |\n",
    "|      cells.6.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|       cells.6.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.6.conv_residual.channel_scale    |    512     |\n",
    "|     cells.6.conv_residual.conv.weight     |     0      |\n",
    "|      cells.6.conv_residual.conv.bias      |     0      |\n",
    "|  cells.6.conv_residual.batchnorm2d.weight |     0      |\n",
    "|   cells.6.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|          cells.7.cell_convolution         |     1      |\n",
    "|        cells.7.cnn.0.channel_scale        |    256     |\n",
    "|         cells.7.cnn.0.conv.weight         |     0      |\n",
    "|          cells.7.cnn.0.conv.bias          |     0      |\n",
    "|      cells.7.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|       cells.7.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.7.cnn.1.channel_scale        |    256     |\n",
    "|         cells.7.cnn.1.conv.weight         |     0      |\n",
    "|          cells.7.cnn.1.conv.bias          |     0      |\n",
    "|      cells.7.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|       cells.7.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.7.cnn.2.channel_scale        |    1024    |\n",
    "|         cells.7.cnn.2.conv.weight         |     0      |\n",
    "|          cells.7.cnn.2.conv.bias          |     0      |\n",
    "|      cells.7.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|       cells.7.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.7.conv_residual.channel_scale    |    1024    |\n",
    "|     cells.7.conv_residual.conv.weight     |     0      |\n",
    "|      cells.7.conv_residual.conv.bias      |     0      |\n",
    "|  cells.7.conv_residual.batchnorm2d.weight |     0      |\n",
    "|   cells.7.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|          cells.8.cell_convolution         |     1      |\n",
    "|        cells.8.cnn.0.channel_scale        |    256     |\n",
    "|         cells.8.cnn.0.conv.weight         |     0      |\n",
    "|          cells.8.cnn.0.conv.bias          |     0      |\n",
    "|      cells.8.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|       cells.8.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.8.cnn.1.channel_scale        |    256     |\n",
    "|         cells.8.cnn.1.conv.weight         |     0      |\n",
    "|          cells.8.cnn.1.conv.bias          |     0      |\n",
    "|      cells.8.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|       cells.8.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.8.cnn.2.channel_scale        |    1024    |\n",
    "|         cells.8.cnn.2.conv.weight         |     0      |\n",
    "|          cells.8.cnn.2.conv.bias          |     0      |\n",
    "|      cells.8.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|       cells.8.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.8.conv_residual.channel_scale    |    1024    |\n",
    "|     cells.8.conv_residual.conv.weight     |     0      |\n",
    "|      cells.8.conv_residual.conv.bias      |     0      |\n",
    "|  cells.8.conv_residual.batchnorm2d.weight |     0      |\n",
    "|   cells.8.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|          cells.9.cell_convolution         |     1      |\n",
    "|        cells.9.cnn.0.channel_scale        |    256     |\n",
    "|         cells.9.cnn.0.conv.weight         |     0      |\n",
    "|          cells.9.cnn.0.conv.bias          |     0      |\n",
    "|      cells.9.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|       cells.9.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.9.cnn.1.channel_scale        |    256     |\n",
    "|         cells.9.cnn.1.conv.weight         |     0      |\n",
    "|          cells.9.cnn.1.conv.bias          |     0      |\n",
    "|      cells.9.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|       cells.9.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.9.cnn.2.channel_scale        |    1024    |\n",
    "|         cells.9.cnn.2.conv.weight         |     0      |\n",
    "|          cells.9.cnn.2.conv.bias          |     0      |\n",
    "|      cells.9.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|       cells.9.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.9.conv_residual.channel_scale    |    1024    |\n",
    "|     cells.9.conv_residual.conv.weight     |     0      |\n",
    "|      cells.9.conv_residual.conv.bias      |     0      |\n",
    "|  cells.9.conv_residual.batchnorm2d.weight |     0      |\n",
    "|   cells.9.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|         cells.10.cell_convolution         |     1      |\n",
    "|        cells.10.cnn.0.channel_scale       |    256     |\n",
    "|         cells.10.cnn.0.conv.weight        |     0      |\n",
    "|          cells.10.cnn.0.conv.bias         |     0      |\n",
    "|     cells.10.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|      cells.10.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.10.cnn.1.channel_scale       |    256     |\n",
    "|         cells.10.cnn.1.conv.weight        |     0      |\n",
    "|          cells.10.cnn.1.conv.bias         |     0      |\n",
    "|     cells.10.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|      cells.10.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.10.cnn.2.channel_scale       |    1024    |\n",
    "|         cells.10.cnn.2.conv.weight        |     0      |\n",
    "|          cells.10.cnn.2.conv.bias         |     0      |\n",
    "|     cells.10.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|      cells.10.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.10.conv_residual.channel_scale   |    1024    |\n",
    "|     cells.10.conv_residual.conv.weight    |     0      |\n",
    "|      cells.10.conv_residual.conv.bias     |     0      |\n",
    "| cells.10.conv_residual.batchnorm2d.weight |     0      |\n",
    "|  cells.10.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|         cells.11.cell_convolution         |     1      |\n",
    "|        cells.11.cnn.0.channel_scale       |    256     |\n",
    "|         cells.11.cnn.0.conv.weight        |     0      |\n",
    "|          cells.11.cnn.0.conv.bias         |     0      |\n",
    "|     cells.11.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|      cells.11.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.11.cnn.1.channel_scale       |    256     |\n",
    "|         cells.11.cnn.1.conv.weight        |     0      |\n",
    "|          cells.11.cnn.1.conv.bias         |     0      |\n",
    "|     cells.11.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|      cells.11.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.11.cnn.2.channel_scale       |    1024    |\n",
    "|         cells.11.cnn.2.conv.weight        |     0      |\n",
    "|          cells.11.cnn.2.conv.bias         |     0      |\n",
    "|     cells.11.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|      cells.11.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.11.conv_residual.channel_scale   |    1024    |\n",
    "|     cells.11.conv_residual.conv.weight    |     0      |\n",
    "|      cells.11.conv_residual.conv.bias     |     0      |\n",
    "| cells.11.conv_residual.batchnorm2d.weight |     0      |\n",
    "|  cells.11.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|         cells.12.cell_convolution         |     1      |\n",
    "|        cells.12.cnn.0.channel_scale       |    256     |\n",
    "|         cells.12.cnn.0.conv.weight        |     0      |\n",
    "|          cells.12.cnn.0.conv.bias         |     0      |\n",
    "|     cells.12.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|      cells.12.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.12.cnn.1.channel_scale       |    256     |\n",
    "|         cells.12.cnn.1.conv.weight        |     0      |\n",
    "|          cells.12.cnn.1.conv.bias         |     0      |\n",
    "|     cells.12.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|      cells.12.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.12.cnn.2.channel_scale       |    1024    |\n",
    "|         cells.12.cnn.2.conv.weight        |     0      |\n",
    "|          cells.12.cnn.2.conv.bias         |     0      |\n",
    "|     cells.12.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|      cells.12.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.12.conv_residual.channel_scale   |    1024    |\n",
    "|     cells.12.conv_residual.conv.weight    |     0      |\n",
    "|      cells.12.conv_residual.conv.bias     |     0      |\n",
    "| cells.12.conv_residual.batchnorm2d.weight |     0      |\n",
    "|  cells.12.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|         cells.13.cell_convolution         |     1      |\n",
    "|        cells.13.cnn.0.channel_scale       |    512     |\n",
    "|         cells.13.cnn.0.conv.weight        |     0      |\n",
    "|          cells.13.cnn.0.conv.bias         |     0      |\n",
    "|     cells.13.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|      cells.13.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.13.cnn.1.channel_scale       |    512     |\n",
    "|         cells.13.cnn.1.conv.weight        |     0      |\n",
    "|          cells.13.cnn.1.conv.bias         |     0      |\n",
    "|     cells.13.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|      cells.13.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.13.cnn.2.channel_scale       |    2048    |\n",
    "|         cells.13.cnn.2.conv.weight        |     0      |\n",
    "|          cells.13.cnn.2.conv.bias         |     0      |\n",
    "|     cells.13.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|      cells.13.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.13.conv_residual.channel_scale   |    2048    |\n",
    "|     cells.13.conv_residual.conv.weight    |     0      |\n",
    "|      cells.13.conv_residual.conv.bias     |     0      |\n",
    "| cells.13.conv_residual.batchnorm2d.weight |     0      |\n",
    "|  cells.13.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|         cells.14.cell_convolution         |     1      |\n",
    "|        cells.14.cnn.0.channel_scale       |    512     |\n",
    "|         cells.14.cnn.0.conv.weight        |     0      |\n",
    "|          cells.14.cnn.0.conv.bias         |     0      |\n",
    "|     cells.14.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|      cells.14.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.14.cnn.1.channel_scale       |    512     |\n",
    "|         cells.14.cnn.1.conv.weight        |     0      |\n",
    "|          cells.14.cnn.1.conv.bias         |     0      |\n",
    "|     cells.14.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|      cells.14.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.14.cnn.2.channel_scale       |    2048    |\n",
    "|         cells.14.cnn.2.conv.weight        |     0      |\n",
    "|          cells.14.cnn.2.conv.bias         |     0      |\n",
    "|     cells.14.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|      cells.14.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.14.conv_residual.channel_scale   |    2048    |\n",
    "|     cells.14.conv_residual.conv.weight    |     0      |\n",
    "|      cells.14.conv_residual.conv.bias     |     0      |\n",
    "| cells.14.conv_residual.batchnorm2d.weight |     0      |\n",
    "|  cells.14.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|         cells.15.cell_convolution         |     1      |\n",
    "|        cells.15.cnn.0.channel_scale       |    512     |\n",
    "|         cells.15.cnn.0.conv.weight        |     0      |\n",
    "|          cells.15.cnn.0.conv.bias         |     0      |\n",
    "|     cells.15.cnn.0.batchnorm2d.weight     |     0      |\n",
    "|      cells.15.cnn.0.batchnorm2d.bias      |     0      |\n",
    "|        cells.15.cnn.1.channel_scale       |    512     |\n",
    "|         cells.15.cnn.1.conv.weight        |     0      |\n",
    "|          cells.15.cnn.1.conv.bias         |     0      |\n",
    "|     cells.15.cnn.1.batchnorm2d.weight     |     0      |\n",
    "|      cells.15.cnn.1.batchnorm2d.bias      |     0      |\n",
    "|        cells.15.cnn.2.channel_scale       |    2048    |\n",
    "|         cells.15.cnn.2.conv.weight        |     0      |\n",
    "|          cells.15.cnn.2.conv.bias         |     0      |\n",
    "|     cells.15.cnn.2.batchnorm2d.weight     |     0      |\n",
    "|      cells.15.cnn.2.batchnorm2d.bias      |     0      |\n",
    "|    cells.15.conv_residual.channel_scale   |    2048    |\n",
    "|     cells.15.conv_residual.conv.weight    |     0      |\n",
    "|      cells.15.conv_residual.conv.bias     |     0      |\n",
    "| cells.15.conv_residual.batchnorm2d.weight |     0      |\n",
    "|  cells.15.conv_residual.batchnorm2d.bias  |     0      |\n",
    "|                fc.fc.weight               |     0      |\n",
    "|                 fc.fc.bias                |     10     |\n",
    "+-------------------------------------------+------------+\n",
    "Total Trainable Params: 37786\n",
    "Reduced parameters 37786/38146522 = 0.0009905490204323215\n",
    "Traceback (most recent call last):\n",
    "  File \"networks/cell2d.py\", line 1049, in <module>\n",
    "    result = Test(args)\n",
    "  File \"networks/cell2d.py\", line 929, in Test\n",
    "    plotsearch = PlotSearch(classify)\n",
    "  File \"networks/cell2d.py\", line 785, in __init__\n",
    "    architecture_weights, total_trainable_weights, cell_weights = network.ArchitectureWeights()\n",
    "  File \"networks/cell2d.py\", line 703, in ArchitectureWeights\n",
    "    cell_archatecture_weights, cell_total_trainable_weights, cell_weight = in_cell.ArchitectureWeights()\n",
    "  File \"networks/cell2d.py\", line 463, in ArchitectureWeights\n",
    "    layer_weight, _, conv_weights  = l.ArchitectureWeights()\n",
    "  File \"networks/cell2d.py\", line 151, in ArchitectureWeights\n",
    "    conv_weights = torch.tanh(self.weight_gain*weight_scale*torch.linalg.norm(self.conv.weight, dim=(1,2,3)))\n",
    "RuntimeError: The size of tensor a (64) must match the size of tensor b (0) at non-singleton dimension 0\n",
    "PlotSearch finish\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cef0930-7cf9-4028-8619-c08bcf7ffaac",
   "metadata": {},
   "source": [
    "12 January 2022\n",
    "- Error in normalized weights is because L2 norm is not normzlized based on the number of elments in norm.  The norm of large convolutions resulted in a larger norm than smaller convolutions.\n",
    "- L2 norm devided by the square root of the number of elements results in consistent bahavior across different tensor sizes:\n",
    "``` python\n",
    "def ArchitectureWeights(self):\n",
    "    weight_scale = self.sigmoid(self.sigmoid_scale*self.channel_scale)\n",
    "    norm = torch.linalg.norm(self.conv.weight, dim=(1,2,3))/np.sqrt(np.product(self.conv.weight.shape[1:]))\n",
    "    conv_weights = torch.tanh(self.weight_gain*weight_scale*norm)\n",
    "```\n",
    "- Next, include a by-stable function in the objective for channel enable/disable so the optomizer will be rewarded for either turning the channel on or off and avoid a middle value\n",
    "- How to handel zeroing out all convolutions?\n",
    "- Disabled batch norm to prevent compensating for a zeroed out channel by brining it back with batch norm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90363603-3329-4cf4-99f1-0f2facc999ce",
   "metadata": {},
   "source": [
    "13 January 2022\n",
    "- Training was resulting in zero-sized convolutions\n",
    "- Cause - initialized channel pruning to 0.5.  \n",
    "- Architecture wights was product of convolution norm (~ 0.6) * channel scale (~0.5) = ~0.3\n",
    "- Cutoff was 0.5 = results in pruning all of the convolutions\n",
    "- \n",
    "``` python\n",
    "class ConvBR(nn.Module):\n",
    "    def __init__(self, \n",
    "       self.channel_scale = nn.Parameter(torch.zeros(self.out_channels, dtype=torch.float))\n",
    "    def ArchitectureWeights(self):\n",
    "        weight_scale = self.sigmoid(self.sigmoid_scale*self.channel_scale)\n",
    "        conv_weights = torch.tanh(self.weight_gain*weight_scale*torch.linalg.norm(self.conv.weight, dim=(1,2,3)))\n",
    "\n",
    "```\n",
    "- Fix: change con_weights average of channel_scale and convolutio norm\n",
    "```python\n",
    "    def ArchitectureWeights(self):\n",
    "        weight_scale = self.sigmoid(self.sigmoid_scale*self.channel_scale)\n",
    "        norm = torch.linalg.norm(self.conv.weight, dim=(1,2,3))/np.sqrt(np.product(self.conv.weight.shape[1:]))\n",
    "        conv_weights = (torch.tanh(self.weight_gain*norm)+weight_scale)/2.0\n",
    "\n",
    "```\n",
    "- I then needed to reduce the -k_structure default argument (trying 1e-3 now) to accuracy is searched preferentially.\n",
    "- Add stabilization normalized gaussian function to push ConvBR::channel_scale to 0 or 1.  Add to loss so channels preferentially are on or off\n",
    "- record class weights as video\n",
    "- Add class weighs to tensorboard\n",
    "- What d cleass weights do when search_structure us false?\n",
    "- Add fully connected layer to model erosion\n",
    "- How to esnsure the eroded model is feasible?\n",
    "- Eroded weights should not be contributing significantly to model accuracy.  \n",
    "- Is relaxation of the convolution outputs a poor model of the removed weight?  \n",
    "- Do max pooling and batch normalizaton compensate too effectively for the weight change?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c87bb-6fd8-47b4-bb9b-e2a9cdcf98ba",
   "metadata": {},
   "source": [
    "14 January 2022\n",
    "- The trained networks were very stubborn about minimizing network size\n",
    "- After initial training without or with very little pruning, I then tried to increase the pruning with very little affect\n",
    "- Added a gradient plot following the structure of the class_weights plot\n",
    "- Found that the architecture gradent was in the trange of 1e-6 and the classification gradient was in the range of 1e-2\n",
    "- By increasing k_structure, I was able to proportionally incrase the class weight norms to a similar value to classificaiton norms\n",
    "- At this point, classificaiton loss on the test set minimized at a bout 1000 batches and then incrased.  \n",
    "- Set structural loss to target a specific architecture level and  trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b6b85e-be14-44a2-bc1a-4be625ec380a",
   "metadata": {},
   "source": [
    "15 January 2022\n",
    "- Added gradient norm visualization\n",
    "- Needed to increase k_structure to 1.0e2 or 1.0e3 to get the structure minimization.  1.0e3 convers structure well\n",
    "- Need to handle 0 size convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01269e6c",
   "metadata": {},
   "source": [
    "17 January 2022\n",
    "- Added image augmentation, removed dropout\n",
    "- CIFAR-10 Resnet 18, 75 epochs, -target_structure=1.0e0, final test accuracy ~0.8583, nas_20220117_rn18_00\n",
    "- CIFAR-10 Resnet 18, 20 epochs, -target_structure=1.0e0, -learning_rate=0.001, final test accuracy ~0.8743, nas_20220117_rn18_01\n",
    "- CIFSR-10 -target_structure=1.0e-1, 10 epochs, -learning_rate=0.01, -target_structure=1.0e-1, final test accuracy ~.8496, nas_20220117_rn18_02\n",
    "- CIFAR-10 Resnet 18, 20 epochs, Prune, Reduced parameters 5145795/11498898 = 0.4475033172744032, -learning_rate=0.001,\n",
    "learning_rate=0.01, -target_structure=1.0e-1, final test accuracy ~.8496, nas_20220117_rn18_02\n",
    "- nas_20220117_rn18_04 zero's out several channels.  Use this to figure out what I should do when this happens.  I would like to burn out the convolution and burn open the residual but that would mean growing the residual channel.  Maybe freezing the residual would be better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
