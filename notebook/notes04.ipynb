{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLLib Development Notes\n",
    "\n",
    "Reverse time order - Newest on top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27 May, 2022\n",
    "- Rebuild dockerfile-torch-train:latest locally on HIOCNN - Maybe the failure was not pulling the latest \"latest\" container and was running on old code\n",
    "- Changed to 1 worker\n",
    "- Restarted CRISP coco training on HIOCNN\n",
    "- Running this morning 7 hours later without failure\n",
    "- Tensorboard is starting at step 18.  I may not be successfully combining runs into a single tensorboard.\n",
    "- Try moving each step into a subdirectory.  They should be identified individually then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26 May, 2022\n",
    "- Added \"except\" to DecodeImage:\n",
    "```python\n",
    "                try:\n",
    "                    img = cv2.imdecode(imgbuff, flags=self.imflags)\n",
    "                except:\n",
    "                    print (\"CocoStore::DecodeImage {}/{} cv2.imdecode exception i={}\".format(bucket, objectname, i))\n",
    "                    img = None\n",
    "```\n",
    "- Failed again on HIOCNNN in the same way\n",
    "```cmd\n",
    "INFO:pytorch_profiler:Run tb loaded\n",
    "INFO:pytorch_profiler:Add run tb\n",
    "Traceback (most recent call last):\n",
    "  File \"networks/network2d.py\", line 1020, in <module>\n",
    "    result = main(args)\n",
    "  File \"networks/network2d.py\", line 968, in main\n",
    "    results = Train(args, s3, s3def, class_dictionary, segment, device, results)\n",
    "  File \"networks/network2d.py\", line 694, in Train\n",
    "    data = next(iTest)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
    "    data = self._next_data()\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
    "    return self._process_data(data)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
    "    data.reraise()\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/_utils.py\", line 438, in reraise\n",
    "    raise exception\n",
    "RuntimeError: Caught RuntimeError in DataLoader worker process 0.\n",
    "Original Traceback (most recent call last):\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
    "    data = fetcher.fetch(index)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
    "    return self.collate_fn(data)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torchdatasetutil/cocostore.py\", line 246, in collate_fn\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 84, in default_collate\n",
    "    return [default_collate(samples) for samples in transposed]\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 84, in <listcomp>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "24 May, 2022\n",
    "- Another data read failure with CRISP on COCO dataset:\n",
    "```\n",
    "[  3/50,    240/14785]  loss: 4.86039e-01|4.14557e-01 cross-entropy loss: 4.15798e-01|4.04716e-01 remaining: 9.84038e-01 (train|test) step\n",
    "time: 0.594\n",
    "\n",
    "NOTE: Using experimental fast data loading logic. To disable, pass\n",
    "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
    "    https://github.com/tensorflow/tensorboard/issues/4784\n",
    "\n",
    "INFO:pytorch_profiler:Monitor runs begin\n",
    "WARNING:urllib3.connectionpool:Retrying (Retry(total=9, connect=5, read=3, redirect=5, status=None)) after connection broken by 'ProtocolEr\n",
    "ror('Connection aborted.', BadStatusLine('4póO~%\\x1b\\x9bw?\\x8eüôÆéÂØ9ÇP°]\\x8bmå\\'_|ÖèÔèL Úk\\x88]\\x8dú]]Ï^¿\\x96*0§@z)f*\\x9b\\x98\\x9a¾wªV\\x81«\n",
    "´¥\\xad°Ô¦\\x96í\\x89Ù·ñ{\\x0e9\\x1døÁ_\\x82-\\'0*\\x91c\"Ì)Ä\\x84áSõ\\x12\\x9f$\\x96\\x94Ðq*Qµ\\x87áîIO×\\tK\\x86N3\\x1aÚ\\x16wF\\x10«\\x10êM©\\x11ã¶\\x17~\\t\\x07\n",
    "\\x93Ï[â$k¯½Í[·me\\x03U¾ä\\x80\\x90\\x9fÝ-µy\\x83m\\x97p\\x0f7ãùaV5ä\\x9doÓä\\x8eep!¤/\\r:©\\x01%µI\\x0e\\\\Þü\\x80}¾yÁd\\x05¢Ç5Q ~\\x8e\\x1a\\x0ekñ\\x99%\\x17H3\n",
    "\\x80öO{\\x8eÿ\\x00\\x18\\x1b¯]\\x94\\x17\\x9fÙ\\xadÒÖ5m\\x87ÊUMÞE¬Xã§?Ó\\x06ìïþº\\x0e\\x88½\\xad´\\x86»æµ]\\x95\\x19Ä¤.l7V¡¹;B\\x93´|þ¸ ²,\\n'))': /mllib/dat\n",
    "a/coco/val2017/000000427655.jpg\n",
    "Corrupt JPEG data: premature end of data segment\n",
    "INFO:pytorch_profiler:Find run directory /app/tb\n",
    "INFO:pytorch_profiler:Load run tb\n",
    "INFO:pytorch_profiler:started all processing\n",
    "INFO:pytorch_profiler:Run tb loaded\n",
    "INFO:pytorch_profiler:Add run tb\n",
    "WARNING:urllib3.connectionpool:Retrying (Retry(total=9, connect=5, read=3, redirect=5, status=None)) after connection broken by 'ProtocolEr\n",
    "ror('Connection aborted.', BadStatusLine('\\x08Ä\"\\')´\\x8f×\\x8e\\x8a;£\\x0bu\\x04Ä¡ø\\x86qì:\\x88úP!=Mç©X\\x98\\t9<ýsÑ2\\x9c\\x19Dú\\x9cÇ\\t\\x0cÞ[nVU\\x0\n",
    "7\\x1e\\x98õéútz\\x84\\r\\\\Bæª)\\x9cd\\x0f\\x89qÃ{~]Hfé¥®\\x91Xg+ë\\x9fÌtêiÍ\\x01`¡xx9<\\x03\\x8e\\x84¢.\\x04L-Å£Ë\\x90²º\\x82}\\x7f/ùtÅi\\x19NÐláw4öä\\x99\\x0c\n",
    "»r¸Ç\\x1dUº±\\x9c+&Sê\\x93ÔÚ\\x80\\x80\\x16Le½ÇA\\x95\\x8cç)áJFR:kCÈ¥Z78ã\\x81ýzr¥p>êK(#d°ìUQ\\t\\x1bÇ©\\x1e£Ó¤\\x0b\\x8ce\\x07[#`Ñó.÷]«\\x1e2\\x1biÉü¿¯DëÐ7\n",
    "M¶ÈÌ\\x85Äßt×Ý\\x8c²Ç$\\x8d/9Vöêu½Ð\"\\n'))': /mllib/data/coco/train2017/000000341017.jpg\n",
    "Corrupt JPEG data: premature end of data segment\n",
    "Traceback (most recent call last):\n",
    "  File \"networks/network2d.py\", line 1020, in <module>\n",
    "    result = main(args)\n",
    "  File \"networks/network2d.py\", line 968, in main\n",
    "    results = Train(args, s3, s3def, class_dictionary, segment, device, results)\n",
    "  File \"networks/network2d.py\", line 694, in Train\n",
    "    data = next(iTest)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
    "    data = self._next_data()\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
    "    return self._process_data(data)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
    "    data.reraise()\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/_utils.py\", line 438, in reraise\n",
    "    raise exception\n",
    "RuntimeError: Caught RuntimeError in DataLoader worker process 0.\n",
    "Original Traceback (most recent call last):\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
    "    data = fetcher.fetch(index)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
    "    return self.collate_fn(data)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torchdatasetutil/cocostore.py\", line 237, in collate_fn\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 84, in default_collate\n",
    "    return [default_collate(samples) for samples in transposed]\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 84, in <listcomp>\n",
    "    return [default_collate(samples) for samples in transposed]\n",
    "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 56, in default_collate\n",
    "    return torch.stack(batch, 0, out=out)\n",
    "RuntimeError: stack expects each tensor to be equal size, but got [480, 512] at entry 0 and [442, 512] at entry 5\n",
    "```\n",
    "- Adding S3-level retries didn't appear to fix the problem\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23 May, 2022\n",
    "- Training failure on HIOCNN on the weekend run:\n",
    "    ```cmd\n",
    "    [ 13/50,    240/14785]  loss: 3.23336e-01|1.37674e-01 cross-entropy loss: 3.68384e-01|1.28495e-01 remaining\n",
    "    : 9.17939e-01 (train|test) step time: 0.595\n",
    "    100%|██████████| 2/2 [00:00<00:00,  7.88it/s]\n",
    "\n",
    "    NOTE: Using experimental fast data loading logic. To disable, pass\n",
    "        \"--load_fast=false\" and report issues on GitHub. More details:\n",
    "        https://github.com/tensorflow/tensorboard/issues/4784\n",
    "\n",
    "    INFO:pytorch_profiler:Monitor runs begin\n",
    "    INFO:pytorch_profiler:Find run directory /app/tb\n",
    "    INFO:pytorch_profiler:Load run tb\n",
    "    INFO:pytorch_profiler:started all processing\n",
    "    INFO:pytorch_profiler:Run tb loaded\n",
    "    INFO:pytorch_profiler:Add run tb\n",
    "    WARNING:tensorboard:In 3.0, this warning will become an error:\n",
    "    Requires default-src for Content-Security-Policy\n",
    "    WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None\n",
    "    )) after connection broken by 'ProtocolError('Connection aborted.', BadStatusLine('Kå\\x08\\x9d\\x00ó½¾\\x18ä\\x\n",
    "    80\\x000\\x94Mc\\x9a\\x8d\\x80\\x8dÁ8\\\\R[ôGÒ-n7©J\\t)T\\x01¹Â{\\x93Úm¶QAK\\x10B\\x86\\x92yíþ°\\x94\\x94\\x12r\\x17¢\\xa0¬\\x9\n",
    "    1ª\\x06Ð0à\\x8aÑ¸¤\\x9d%ÍPæãc÷l&Rçþ)4j\\x925B\\x89\\x8b\\x1b\\x0c6\\x93Zò¿&\\x98<\\x12\\x95-J\\x04O\\x8b¦:©\\x11®/m\\x14àÃ-\n",
    "    7\\x1e2U\\x17½ð\\x17:°\\x95ÍJ¾êRÙ\\x1eñ;Î\\x04x´Òê\\x19M®Ð%õ\\x14\\x04ÊEÔI\\x89¶\"ºÊáè\\x11\\x94ùy¤\\x1e\\tÞàtÀ\\x1c\\x01R£.\n",
    "    bnÌ\\x96ã\\x8b-\\x9dDLm\\x13\\x80á¥X:G9»QÙ.N*\\x9cm:eV278YeÚËPY\\x11/Sð?¦Q\\x846\\x90\\x12\\x13\\n'))': /mllib/data/coc\n",
    "    o/train2017/000000528284.jpg\n",
    "    Corrupt JPEG data: premature end of data segment\n",
    "    Traceback (most recent call last):\n",
    "    File \"networks/network2d.py\", line 1021, in <module>\n",
    "        result = main(args)\n",
    "    File \"networks/network2d.py\", line 969, in main\n",
    "        results = Train(args, s3, s3def, class_dictionary, segment, device, results)\n",
    "    File \"networks/network2d.py\", line 695, in Train\n",
    "        data = next(iTest)\n",
    "    File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
    "        data = self._next_data()\n",
    "    File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
    "        return self._process_data(data)\n",
    "    File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
    "        data.reraise()\n",
    "    File \"/opt/conda/lib/python3.8/site-packages/torch/_utils.py\", line 438, in reraise\n",
    "        raise exception\n",
    "    RuntimeError: Caught RuntimeError in DataLoader worker process 0.\n",
    "    Original Traceback (most recent call last):\n",
    "    File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
    "        data = fetcher.fetch(index)\n",
    "    File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
    "        return self.collate_fn(data)\n",
    "    File \"/opt/conda/lib/python3.8/site-packages/torchdatasetutil/cocostore.py\", line 235, in collate_fn\n",
    "        return torch.utils.data.dataloader.default_collate(batch)\n",
    "    File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 84, in default_col\n",
    "    late\n",
    "        return [default_collate(samples) for samples in transposed]\n",
    "    File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 84, in <listcomp>\n",
    "        return [default_collate(samples) for samples in transposed]\n",
    "    File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 56, in default_col\n",
    "    late\n",
    "        return torch.stack(batch, 0, out=out)\n",
    "    RuntimeError: stack expects each tensor to be equal size, but got [480, 512] at entry 0 and [393, 512] at e\n",
    "    ntry 7\n",
    "    ```\n",
    "- It looks like a read failure resulted in an incorrect image size.\n",
    "- Added retries to MINIO reads\n",
    "- Can network reads be made more reliable\n",
    "- Because this read failure resulted in an incorrect image size rather than a null buffer, we hat a failure in \"cocostore.py\", line 235, in collate_fn\" rather than loading the next image\n",
    "- Could this failure have been correlated with my using the MINIO console?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21 May, 2022\n",
    "- Successfully plot tensorboard across multiple steps in workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19 May 2022\n",
    "- Code is in place to have a continuous tensorboard though a multi-step CRISP training as an Argo workflow\n",
    "- Failure on first workflow step with an empty artifact input\n",
    "    ```cmd\n",
    "    blarson@ipc001:/data/git/mllib$ py utils/workflow.py -s ipc001 -r workflow/seg.yaml -p '{\"output_name\":\"20220519i\", \"target_structure\":0.0, \"batch_size\":3, \"debug\": true, \"min\": true }'\n",
    "    url: https://192.168.0.155:30992/api/v1/workflows/ml \n",
    "    status_code: 500 \n",
    "    response: {\"code\":2,\"message\":\"templates.train-crisp.tasks.normalized-train templates.train inputs.artifacts.prevresultspath was not supplied\"}\n",
    "    ```\n",
    "- see if I can solve this with [conditional artifcats](https://github.com/argoproj/argo-workflows/blob/master/examples/conditional-artifacts.yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17 May 2022\n",
    "- Adding artifcats to [../workflow/seg.yaml](../workflow/seg.yaml) to pass log intex between steps to produce one continuous tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16 May 2022\n",
    "1. How to experiment on convergence?\n",
    "    - Which convergence tests apply to CNN convergence\n",
    "        <svg id=\"svg\" viewbox=\"21.659997940063477,68.5999984741211,268.79998779296875,193.60000610351562\" style=\"height:193.60000610351562\"><path d=\"M 137.26,78.6 L 136.46,79.4 L 136.46,81 L 136.46,84.2 L 136.46,87.4 L 136.46,92.2 L 136.46,101 L 135.66,109 L 135.66,117 L 135.66,125 L 135.66,136.2 L 135.66,144.2 L 135.66,152.2 L 135.66,161 L 135.66,167.4 L 135.66,173 L 135.66,177.8 L 135.66,182.6 L 134.86,185.8 L 134.86,189.8 L 134.06,192.2 L 133.26,195.4 L 132.46,197.8 L 131.66,199.4 L 130.86,201.8 L 130.86,202.6 L 130.86,204.2 L 130.06,205.8 L 130.06,206.6 L 130.06,208.2 L 130.06,209 L 130.86,209 L 131.66,209 L 132.46,209 L 134.06,208.2 L 135.66,208.2 L 138.86,207.4 L 142.86,207.4 L 150.06,206.6 L 157.26,206.6 L 166.86,205.8 L 177.26,205 L 189.26,204.2 L 204.46,204.2 L 216.46,203.4 L 230.06,203.4 L 242.06,203.4 L 255.66,202.6 L 265.26,201.8 L 272.46,201 L 278.06,200.2 L 280.46,200.2\" fill=\"none\" stroke=\"#6190e8\" stroke-width=\"2\"></path><path d=\"M 254.86,81.8 L 254.86,83.4 L 254.86,86.6 L 254.06,89 L 253.26,93.8 L 252.46,97.8 L 250.86,103.4 L 248.46,109 L 246.06,114.6 L 243.66,120.2 L 239.66,127.4 L 234.86,134.6 L 231.66,139.4 L 226.86,144.2 L 221.26,149 L 214.06,155.4 L 208.46,160.2 L 202.06,164.2 L 195.66,168.2 L 189.26,172.2 L 184.46,174.6 L 178.86,177 L 170.86,180.2 L 165.26,183.4 L 161.26,185.8 L 156.46,187.4 L 151.66,189 L 150.06,189 L 149.26,189\" fill=\"none\" stroke=\"#6190e8\" stroke-width=\"2\"></path>  <text font-family=\"inherit\" font-size=\"14\" fill=\"#6190e8\" x=\"140.46\" y=\"249\">Cross entropy loss</text><text font-family=\"inherit\" font-size=\"14\" fill=\"#6190e8\" x=\"32.46\" y=\"149\">Architecture Loss</text></svg> \n",
    "\n",
    "    - Does convergence depend on initial conditions?\n",
    "    - Does convergence depend on search method?\n",
    "1. How to experiment on relaxation?\n",
    "    - Output difference between relaxed model and pruned model\n",
    "    - Objective performance of relaxed model and retrained pruned model\n",
    "    - Sparsity of pruned model\n",
    "1. How effectively is the space searched\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 May 2021\n",
    "- Objective: Initialize model with pretrained weights to improve training and convergence\n",
    "- Observe if there is a relationship between pretrained weights and pruning\n",
    "- Transfer learning: \n",
    "    1. Create full unpruned model\n",
    "    2. model.load_state_dict(<model weights>, strict=False)\n",
    "\n",
    "_Convergence and stability_\n",
    "- There is a lot of discussion of convergence and stability in NAS and structured pruning [STACNAS: TOWARDS STABLE AND CONSISTENT OPTIMIZATION FOR DIFFERENTIABLE NEURAL ARCHITECTURE SEARCH](https://openreview.net/pdf?id=rygpAnEKDH)\n",
    "- Formal methods to evaluate convergence and stability are missing from deep learning optimization literature\n",
    "- Stability [Numerical stability](https://en.wikipedia.org/wiki/Numerical_stability#:~:text=The%20usual%20definition%20of%20numerical,)%20%E2%88%92%20y*%20is%20small.), [Stability theory](https://en.wikipedia.org/wiki/Stability_theory)\n",
    "- Convergence: [Convergent series](https://en.wikipedia.org/wiki/Convergent_series), [Convergence tests](https://en.wikipedia.org/wiki/Convergence_tests), [Conditional convergence](https://en.wikipedia.org/wiki/Conditional_convergence)\n",
    "- Relaxation similarity to Pruned model with various approaches - Nothing, DAIS, weighting basis function\n",
    "- Display pruning map across training\n",
    "- Append Tensorboard across Argo steps\n",
    "- Quick method to view Tensorboard for specific run from Jupyter\n",
    "- Once we can view training, evaluate various approaches:\n",
    "    1. Train -> Prune -> Train -> Prune\n",
    "    1. Simultaneous train & prune\n",
    "    1. Train to specific size & prune\n",
    "    1. Weighting methods from training\n",
    "    1. [Figure 3 Loss Contours](https://openreview.net/pdf?id=SYuJXrXq8tw)\n",
    "    1. [Figure 1 Loss surface](https://arxiv.org/pdf/1712.09913.pdf)\n",
    "- What can be answered about generalization of pruned network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 May 2022\n",
    "- CRISP training of UNET on the LIT dataset takes a few hours\n",
    "- The same parameters on COCO take a few days\n",
    "- The COCO dataset is much more diverse than the LIT dataset\n",
    "- The COCO dataset is 100x larger than the LIT dataset\n",
    "- A6000 GPU efficiency is 70% on COCO\n",
    "- I am only using half the available A6000 memory.  Increasing this should reduce the training time\n",
    "- Look at [Deeplab V3](https://arxiv.org/pdf/1706.05587.pdf) with CRISP\n",
    "- Deeplab V3 : [Pytorch implementation](https://github.com/pytorch/vision/blob/main/torchvision/models/segmentation/deeplabv3.py)\n",
    "- Deeplab V3 \n",
    "    1. encoder\n",
    "        - resnet of different sizes\n",
    "        - mobilenet V3\n",
    "        - ...\n",
    "    1. classifier - FCN head: Conv2d->Batch Norm->relu->Dropout->Conv2d\n",
    "    1. Atrous spatial pyramid pooling: list of Atrous convolutions->BatchNorm->Relu followed\n",
    "    1. Conv->Batch norm->Relu->Dropout across pooling levels\n",
    "- Add per channel relaxation layer following each conv->batch norm\n",
    "- Add network weight metric\n",
    "- Add network pruning function\n",
    "- How to structure this?\n",
    "    1. If search and augment network it can be applied to existing networks without rewriting\n",
    "    1. Instance norm or other norms would be sufficient.  Not just batch norm.\n",
    "    1. Test pruning with and without norms on problems that where convolution scaling can offset continuous relaxation\n",
    "    1. Append norm if needed and relaxation layers to network\n",
    "    1. Efficiently compute architecture loss from augmented network, not class\n",
    "    1. Efficient prune from network, not class\n",
    "    1. Begin with cell2d\n",
    "    1. Explore network-level pruning\n",
    "    1. What is the effect of network-level pruning on stability and convergence\n",
    "    1. Metrics for stability and converence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 May 2022\n",
    "- The past couple of weeks, I have been splitting off code \n",
    "- The python library [pymlutil](https://pypi.org/project/pymlutil/) contains general utility functions\n",
    "- The python library [torchdatasetuitl](https://pypi.org/project/torchdatasetutil/) contains creating and using datasets\n",
    "- I will be removing this code from pymlutil soon.\n",
    "- One goal for this is to enable the dataset to be selected as a parameter\n",
    "- To do this the input channels and format must to be specified in the network creation.\n",
    "- I am adding class_dictionary['input_channels'] and class_dictionary['input_type'] to the class_dictionary.  This way, selecting the class dictionary defines the input type\n",
    "- If the input dataset can be selected by parameter rather than requiring code changes, I would like to enable transfer learning across training sets.\n",
    "- I would like to pick up the Torch pretrained [UNET](https://pytorch.org/hub/mateuszbuda_brain-segmentation-pytorch_unet/) and [Deeplab V3](https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/)\n",
    "- To enable transfer learning, I need to change from torch.load to model.load_state_dict: https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html\n",
    "- torch.load loads the pickled python object which I needed to do previously because pruned state in class variables - e.g. - convolution size after pruning is complete\n",
    "- Transfer learning only may only work for unpruned models\n",
    "- After a model is pruned, how would transfer learning from an unpruned model work?  \n",
    "    - require model pruning weights\n",
    "    - copy parameters based on pruning weights\n",
    "    - easier and same result if you initialize the model just before pruning,\n",
    "    - initialize parameters from transfer learning\n",
    "    - prune model with weights from transfer learning\n",
    "\n",
    "    \"input_channels\":3,\n",
    "    \"input_type\": \"float32\",\n",
    "- For transfer learning, need to handle changes in input channel depth from 1 to 3 and visa versa - for datasets with grayscale and RGB inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 April 2022\n",
    "- Training LIT\n",
    "- Increasing the learning rate 1 2e-4 appears to have pushed the model convergence to train the network to find nothing - always background\n",
    "- There is a heavy class imbalance\n",
    "- Adding class weighting to full training\n",
    "- Next work on switching datasets with parameter\n",
    "- Add cityscapes dataset\n",
    "- Add denoise dataset\n",
    "- Pytorch [Dataset and Dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "- Uses: load, split, train, test, view\n",
    "- [datasets/cocostore.py](../datasets/cocostore.py) - loads coco into torch dataset from S3\n",
    "- [datasets/imstore.py](../datasets/imstore.py) - loads directories of images into torch dataset\n",
    "- [dataset/citytorch.py](../datasets/citytorch.py) - loads cityscapes to a torch dataset \n",
    "- [OpenImages dataset](https://storage.googleapis.com/openimages/web/factsfigures.html)\n",
    "- Disable augmentation on validation images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 April 2022\n",
    "- Scale annealing and prune basis based on start & end points.  \n",
    "- Switch to exponential function where start and end point are specified\n",
    "- Initially grow based on epochs\n",
    "- Experiment with growing based on step to make training more independent of dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 April 2022\n",
    "- CRISP training with pruning basis function crisplit_20220401i_pb00_\n",
    "- Pruned 94% of network while increasing segmentation similarity\n",
    "- May achieve~ 25X speedup\n",
    "- Pruning search not strictly 1 and 0.  \n",
    "\n",
    "\n",
    "[T00cw]: ../img/crisplit_20220401i_pb00_00_cw.png\n",
    "[T01cw]: ../img/crisplit_20220401i_pb00_01_cw.png\n",
    "[T02cw]: ../img/crisplit_20220401i_pb00_02_cw.png\n",
    "[T03cw]: ../img/crisplit_20220401i_pb00_03_cw.png\n",
    "[T00gn]: ../img/crisplit_20220401i_pb00_00_gn.png\n",
    "[T01gn]: ../img/crisplit_20220401i_pb00_01_gn.png\n",
    "[T02gn]: ../img/crisplit_20220401i_pb00_02_gn.png\n",
    "[T03gn]: ../img/crisplit_20220401i_pb00_03_gn.png\n",
    "|  | normalized-train | train | train_fine | prune |\n",
    "|:--:|:--:|:--:|:--:|:--:|\n",
    "|Cross Entropy Loss|0.163|0.0068|0.0112|0.005|\n",
    "|Reamining Ratio   |1.0  |0.132 |0.131 |0.057|\n",
    "|Test similarity   |     |      |0.113 |0.817|\n",
    "| Prune Weights |![][T00cw]|![][T01cw] |![][T02cw] |![][T03cw]|\n",
    "| Gradient Norm |![][T00gn]|![][T01gn] |![][T02gn] |![][T03gn]|\n",
    "\n",
    "- Final losses before pruning:\n",
    "\n",
    "| Loss               | Value    |\n",
    "|:------------------:|:--------:|\n",
    "| cross_entropy_loss | 0.011264 |\n",
    "| architecture_loss  | 0.001306 |\n",
    "| prune_loss         | 0.000196 |\n",
    "\n",
    "- Increasing prune loss should incrase this sepration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class Exponential():\n",
    "    def __init__(self,vx=0.0, vy=0.0, px=1.0, py=1.0, power=2.0):\n",
    "        self.vx = vx\n",
    "        self.vy = vy\n",
    "        self.px = px\n",
    "        self.py = py\n",
    "        if power < 0:\n",
    "            raise ValueError('Exponential error power {} must be >= 0'.format(power))\n",
    "        self.power = power\n",
    "        if px <= vx:\n",
    "            raise ValueError('Exponential error px={} must be > vx'.format(px, vx))\n",
    "        else:\n",
    "            self.a = (py-vy)/np.power(px-vx,power)\n",
    "    def f(self, x):\n",
    "        dx = x-self.vx\n",
    "        y = self.a*np.power(x-self.vx,self.power) + self.vy\n",
    "        return y\n",
    "\n",
    "vx = -1\n",
    "px = 1\n",
    "expf =  Exponential(vx=vx, vy=0.0, px=px, py=1.0, power=2.0)\n",
    "\n",
    "x = np.arange(vx, px, 0.01)\n",
    "plt.plot(x, expf.f(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 April 2022\n",
    "- Prune loss basis function training to 0 size\n",
    "- This resulted in much more agressive pruning\n",
    "- Slightly worse cross entropy loss for train and train_fine\n",
    "- Much worse cross entropy loss for pruned network\n",
    "- The tensorboard plots show a similar timing of the architecture reduction curves but with prune_loss, the architecture settles at a lower level.\n",
    "- Architecture reduction occurs early and converges rapidly compared to cross entropy loss.  \n",
    "- Reduce k_structure from 0.03 to 0.1 to slow architecture search\n",
    "- Increase k_prune_basis from 0.01 to 0.3 to see if the resuls in eliminating fence sittes more effectively\n",
    "- Increase k_prune_exp from 5.0 to 50.0 apply prunce basis later in training\n",
    "\n",
    "[T00cw]: ../img/crisplit_20220331h_pb0_00_cw.png\n",
    "[T01cw]: ../img/crisplit_20220331h_pb0_01_cw.png\n",
    "[T02cw]: ../img/crisplit_20220331h_pb0_02_cw.png\n",
    "[T03cw]: ../img/crisplit_20220331h_pb0_03_cw.png\n",
    "[T00gn]: ../img/crisplit_20220331h_pb0_00_gn.png\n",
    "[T01gn]: ../img/crisplit_20220331h_pb0_01_gn.png\n",
    "[T02gn]: ../img/crisplit_20220331h_pb0_02_gn.png\n",
    "[T03gn]: ../img/crisplit_20220331h_pb0_03_gn.png\n",
    "|  | normalized-train | train | train_fine | prune |\n",
    "|:--:|:--:|:--:|:--:|:--:|\n",
    "|Cross Entropy Loss|0.164|0.032|0.020|0.040|\n",
    "|Reamining Ratio|1.0|0.050|0.041|0.00024|\n",
    "|Test similarity|  |  |0.106|0.028|\n",
    "| Prune Weights |![][T00cw]|![][T01cw] |![][T02cw] |![][T03cw]|\n",
    "| Gradient Norm |![][T00gn]|![][T01gn] |![][T02gn] |![][T03gn]|\n",
    "\n",
    "- Signmod scale as linear function stiffens very quickly.  Want it to be gradual at the beginning and stiffen towards the end of the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def SigmoidScale(step, start_x = 0, end_x = 25, start_y = 0, end_y=100):\n",
    "    kSigmoid = start_y + (end_y-start_y)*step/(end_x-start_x)\n",
    "    return kSigmoid\n",
    "x = np.arange(0.0, 30.0, 0.01)\n",
    "k_prune_exp = 1\n",
    "sigmoid_scale = 5\n",
    "sigmoid_scale_exp = 0.25\n",
    "plt.plot(x, SigmoidScale(x, end_x=25, end_y=150))\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(-1.0, 1.0, 0.01)\n",
    "step =3\n",
    "kSigmoid = SigmoidScale(step, end_x=25, end_y=150)\n",
    "print('kSigmoid({})={}'.format(step, kSigmoid))\n",
    "plt.plot(x, sigmoid(x, k=kSigmoid))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13 April 2022\n",
    "- updated [pymlutil](https://github.com/bhlarson/pymlutil) to deliver new tag and pipy version when excuting ./setup\n",
    "- Added pattern for documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 April 2022\n",
    "- Added imstore.py CreateDataLoaders to load unique datasets for any number of sets with unique parameters \n",
    "- Moving imstore common processing to ImUtil\n",
    "- Move into  library for dataset loading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
